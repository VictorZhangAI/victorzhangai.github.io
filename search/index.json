[{"content":"Handout 13 files, bit arrays, human-readable names\nfs APIs\nfd: listed to the file even if it changes\na file can have multiple links\nfile must have info stored other than directory\ninode: i-number(initial version), link count, count of open FDs\ninode deallocation deferred until last link and FD are gone\ndata stays on disk without power\nhistorically, disks were read/write usually in 512-byte units, called sectors\nin HDD, sub-sector operation are expensive(read-modify-write)\nflash must be erased before written\nxv6 uses 2-sector blocks\nxv6 treats disk as an array of sectors\nmetadata: everything on disk other than file content\non-disk inode: type, nlink, size, addrs[12+1]\ncontent is array of dirents\ndirent: inum, 14-byte filename\nview file system as an on-disk data structure\nfacing concurrency challenges\nlook at block cache\nbread-\u0026gt;bget, watch the bcache\nbcache.lock: description of what\u0026rsquo;s in the cache\nb-\u0026gt;lock: protects just the one buffer\nbcache replacement: bget, brelse\nnamex() ilock()\ngetting a reference separately from locking\nSlides 13 0: syscalls\n1: names+fd\n2: inodes\n3: inode cache \u0026amp; buffer cache\n4: Log\n5: virtio \u0026amp; disk driver\nFD: stdin(0), stdout(1), stderr(2)\nmkfs: generate layout for new FS, the layout will stay static for the lifetime of fs\nindirect block: inode is fixed size, but file could be large\ntree-structure: dir tree layer; inode layer; block layer\nBook Chapter 8 file system must have crash recovery\nblock 0: boot sector\nblock 1: superblock, holds metadata\nblock start at 2 hold the log\ninode, bitmap, data\nbcache: only one kernel thread is using the copy, cache popular blocks\nbcache is a doubly linked-list, main-\u0026gt;binit\nbread-\u0026gt;bget-\u0026gt;sleeplock, scan the bcache\nat most one cached buffer per disk sector\nbrelse to release the buffer\nblock allocator: maintains a free bitmap\nballoc: find the free block, refresh the bitmap, return the block\nbfree: clear the block\non-disk inode: struct dinode\nitable, struct inode to copy dinode into memory\niget, iput\nthere can be many same pointers point to same inode\nhold ilock and release by iunlock\nCode that modifies an in-memory inode writes it to disk with iupdate\niput() doesn’t truncate a file immediately when the link count for the file drops to zero\ndirect/indirect block\nbmap: returns the nth data block for inode ip, or allocate one if not exists\nitrunc: frees blocks and sets inode to 0\ndirectory: has type T_DIR, dirlookup\nnamex -\u0026gt; skipelem\nnamex locks each directory in the path separately\navoid racing by using sleeplocks\nopened file is symboled as struct file\nkept in ftable, filealloc-\u0026gt;filedup-\u0026gt;fileclose-\u0026gt;fileread/filewrite\nfile has no concept of offset\nsys_link, sys_unlink\nsys_link creates a new name for the inode\nusing create, it is easy to implement sys_open, sys_mkdir, and sys_mknod\nLecture 13 (TODO)\n","date":"2025-01-24T08:33:35+08:00","permalink":"https://vzstless.moe/p/xv6-lecture13/","title":"xv6 LECTURE13"},{"content":"Handout 12 why hold p-\u0026gt;lock across threads?\nforbid holding lock when yielding the CPU!\nthreads often wait for conditions\nuse coordination primitives\nuartwrite(): writing thread should give up CPU\nsleep() cannot simply wait the event, or will cause lose wake-up problem\nwhat\u0026rsquo;s wrong if uartwrite() releases the lock before broken_sleep()?\nuartwrite() went to sleep EVEN THOUGH UART TX WAS DONE, nothing will awake uartwrite()\nuse lock to prevent wakeup() from running during the entire window\nsleep() will require a lock to protect its condition, both sleep() and wakeup() will hold the condition lock\ncaller acquired condition lock before calling wakeup()\nacquire p-\u0026gt;lock before releasing condition lock\nwakeup() holds both locks, sleep() just need to hold either\nwakeup() can\u0026rsquo;t proceed until after swtch() completes so wakeup() is guaranteed to see p-\u0026gt;state==SLEEPING and p-\u0026gt;chan==chan\nall uses of sleep are wrapped in a loop, so they re-check\nsleep() doesn\u0026rsquo;t need to know the condition\na thread cannot free all of its own resources\nvoluntarily quit with exit()\nkill() just sets p-\u0026gt;killed flag\nkill() will change SLEEPING into RUNNABLE\nuser space: will die next time it makes a system call or takes a timer interrupt\nkernel space: target will never execute another user instruction but may spend a while yet in the kernel\nBook Chapter 7 (DONE)\nLecture 12 coordination\n1 2 3 4 acquire(p-\u0026gt;lock); p-\u0026gt;state = RUNNABLE; swtch(); release(p-\u0026gt;lock); check whether the thread is runnable\ncalling swtch() requires p-\u0026gt;lock but forbid any other locks\ntwo threads acquire same locks\nfreeze as the process2 will spin forever\ncoordination: sleep() \u0026amp; wakeup()\nbusywait loop\nsleep channel: sleep() and wakeup() could check whether the thread is sleeping\nwhy sleep needs the second argument?\nlost-wakeup problems\nbroken_sleep: simply set the value\nwakeup: for each p in procs: setback the process to runnable\n1 2 3 4 5 6 7 8 9 10 int done; uartwrite(buf) for each c in buf: while not done: sleep(\u0026amp;tx_chan); done = 0; intr() done = 1; wakeup(\u0026amp;tx_chan); add lock \u0026amp; unlock; why not work?\non some other core, UART interrupt is working\nnothing will wake up the broken_sleep, as wakeup() has already happened\ntx_done: a way for interrupt routine to connect the uartintr()\neach typing will cause an interrupt, wakes up the sleeping process for a while then continue sleeping\nwakeup(): run through process table, lock every process, if SLEEPING \u0026amp; same channel, wakeup and release lock\nafter we released the condition lock, the wakeup() will not see this process until it holds process lock\nreader acquire the lock to prevent writer from sleeping\nlast thing sleep() does is acquiring condition lock\nexit() will close files if necessary\nwait() will find the process whose parent process is current process and in state ZOMBIE\nparent will call freeproc() to release resources\nconcurrent exit of parent and child?\nwhy doesn\u0026rsquo;t kill() kills all the processes that could be handled?\nnot allowed in real world, but in xv6, there\u0026rsquo;s no permissions, you can do this\nin Linux, the process to be kill must have the same id as its user id, or killing is not allowed\nwe would never expose broken variants in the file system\n","date":"2025-01-22T14:43:23+08:00","permalink":"https://vzstless.moe/p/xv6-lecture12/","title":"xv6 LECTURE12"},{"content":"Handout 11 concurrency: threads inside the kernel, processes\neach thread, taken alone, executes in an ordinary way\nneed locks when interact\nin xv6, only one user-level thread\nevent-driven and state machine could also use to multitasking\nexecuting: using resources; not executing: save and release\neach process has its own kernel thread\np-\u0026gt;state: running, runnable, sleeping\nuser-\u0026gt;kernel-\u0026gt;scheduler-\u0026gt;kernel-\u0026gt;user\nscheduler thread: one per CPU\nidle scheduler: no running thread\nswtch() returns to scheduler()\nswtch(): saves current registers in xx(a0), restores registers in xx(a1)\nyield() acquires lock, scheduler() releases it\nthe lock is released by a different thread\np-\u0026gt;lock makes steps atomic\nscheduling policy?\nyield() can be called by kerneltrap()\nBook Chapter 7 force switching: sleep \u0026amp; wakeup; long period without sleeping\ncontext: struct context -\u0026gt; struct proc\nswtch: save callee registers, return to instruction pointed by ra register\ncontinue for loop, find a thread, run it\nhold the lock, or different CPU may run same thread\nprocedures that intentionally transfer control to each other via thread switch are sometimes referred to as coroutines\nscheduler: find a process, run, until it is terminated\nmaintain invariants: p-\u0026gt;lock acquires in a thread and releases in another thread\nin multi-core, we can\u0026rsquo;t hold global variables for process, create struct cpu for each core\ntp: stores the core\u0026rsquo;s haltid\nxv6 disable caller interrupt but wait until the struct cpu is returned\nreturn value of myproc() is safe\nconceal actions from one thread to another: sleep \u0026amp; wakeup\nsequence coordination mechanism\nuse a high-level spinlock? most of time it will produce right result but it\u0026rsquo;s expensive\nnaive approach of sleep and wakeup will cause lose wake-up problem\nsolution: the caller must pass condition lock to sleep\nsleep: mark the current process SLEEPING and release the resources of core\nsame channel: see spurious wakeups\npipewrite \u0026amp; piperead are complex applications of sleep \u0026amp; wakeup\nnwrite == nread + PIPESIZE\nwait: wait_lock; exit: reparent\nkill: set p-\u0026gt;killed, wakeup\np-\u0026gt;parent is protected by wait_lock instesd of p-\u0026gt;lock\nround robin: run each process in turn\nlinux\u0026rsquo;s sleep adds a wait queue\nLecture 11 full use of multi-core\nthread: one single exec\ncare the PC\ninterleaving of multiple threads\ninterleave threads\nscheduling: interleave one thread, execute another thread\ncompute-bound?\npre-empitue scheduling: even the code doesn\u0026rsquo;t release the resources of CPU, the kernel will interrupt it by timer\non the contrary, volunteer scheduling\np1 -\u0026gt; tf1 -\u0026gt; kernel stack-\u0026gt; swtch()-\u0026gt; ctx1 -\u0026gt; ctx0 -\u0026gt; swtch() -\u0026gt; scheduler() -\u0026gt; tf2 -\u0026gt; p2\nwhere contexts stores? process structure, p-\u0026gt;context\nprocess vs threads? a process in user; or in kernel; or stored in trapframe and context\nyield(): change the thread into runnable\nno point to save PC as we know we\u0026rsquo;re in swtch\nra will be the point to return\nwhy only half of regs are stored by swtch()? it is called by C function\nwe want the start process also atomic\nwhat we really care is ra\nRISC-V uses general registers instead of floating-point registers\nwe believe the kernel code will infinitely looping without interrupt\nwhy trampoline and swtch must be written in assembly? C is hard to reach ra \u0026amp; sp\nalmost each thread in Linux is a complete process\nallocproc() sets the new context for the process\nthe first call in forkret is about initializing file system and crash recovery\n","date":"2025-01-21T16:58:37+08:00","permalink":"https://vzstless.moe/p/xv6-lecture11/","title":"xv6 LECTURE11"},{"content":"Handout 10 kernel must deal with parallel syscalls\nrace between two cores calling kfree() leads to a page losing\nif multiple cores calls the lock, only one will be returned, other will wait until the lock release\nauto locking? needs explicit comtrol over different regions of code\ndeadlocking problem\nlocks are often not private business of modules\nlock \u0026amp; parallelism may require a whole re-write for the project!\nuse big lock first, big lock is always enough\ncheck and re-lock the lock atomically, pushing down the question into hardware\nspinlock: if locked=1, again the loop, if locked=0, set it to 1, return 0\nif you use locks, you don\u0026rsquo;t need to understand the memory ordering rules, you need them if you want to write exotic \u0026ldquo;lock-free\u0026rdquo; code\nin RISC-V:\n1 2 3 a5 = 1 s1 = \u0026amp;lk-\u0026gt;locked amoswap.w.aq a5, a5, (s1) Book Chapter 6 concurrency: multiple instruction streams are interleaved\nwait() frees child\u0026rsquo;s memory\nrace: the location is accessed concurrently\ncritical section: code covered in acquire() and release()\ninvariants: properties of data structures maintained across operations\ntraditional approach:\n1 2 3 4 5 for(;;) { if(lock == 0) lock = 1; } two cores may reach line 43 at the same time!\namoswap r, a\nswaps the value in address a and register r\nkalloc: a single free list protected by single big lock\ndeadlock: a program requires A to B, the other program requires B to A\ndeadlock requires global lock aquisition\nfile system contains a huge lock-chain\nre-entrant lock: recursive lock\nacquire the lock again: allow the action\nif a spinlock is used by an interrupt handler, a CPU must never hold that lock with interrupts enabled\nnesting level of locks: acquire() calls push_off(); release() calls pop_off();\n__sync_synchronize() tells the compiler not to re-order the code, in fact, it\u0026rsquo;s a memory barrier\nsleeplock: not occupying the core for the lock could last for a long time\nlock can be expensive if CPU requires the same lock at the same time\nBook Chapter 9 acquire() and yield() are released in the scheduler thread\ninode acts as a shard lock\nimplementation of spinlock: no lock at all\nscheduler, different process call fork() at the same time\nLecture 10 apps want to use multiple cores, so kernel must handle multiple syscalls\nthe performance of single core has reached a limit\nwhy locks? avoid race conditions\nmany locks -\u0026gt; more parallelism\naccess a shared data, one is write -\u0026gt; using lock\nlock-free programming\ncould lock be automatic? wrong result, eg: rename(\u0026lsquo;d1/x\u0026rsquo;, d2/y);\nlock avoids wrong updates, make operations atomic\nlock helps maintain an invariant\ndeadlock:\n1 2 3 acquire(lock); ... acquire(lock); order the locks globally\ninternals of m2 must be seen by m1\nrebuild code with locks: start with coarse-grained locks, measure locks are co-required\nlock isolation, redesign\nUART in printf: a buffer with a read pointer and a write pointer\nimplementation of amoswap depends on memory layout\nsame CPU: let operation atomic\nmemory fence: any ld/st instruction aren\u0026rsquo;t allowed to move after this instruction\nuse a race detector\nis fence unnecessary as there are atomic memory instructions?\nthe compiler knows what couldn\u0026rsquo;t be moved\nold OS kernels didn\u0026rsquo;t have lock acquire as they always assume that they run on a single core\n","date":"2025-01-19T07:11:18+08:00","permalink":"https://vzstless.moe/p/xv6-lecture10/","title":"xv6 LECTURE10"},{"content":"Handout 9 CPU \u0026amp; devices: complicated \u0026amp; parallel\nmost code in modern OSes are device drivers\nUART, RS232 port\nUART \u0026amp; FIFO: not using a busy loop, but using interrupts\nUART interrupts if: rx FIFO goes from empty to not-empty, or tx FIFO goes from full to not-full\ndevice interrupts: device -\u0026gt; PLIC -\u0026gt; trap -\u0026gt; usertrap()/kerneltrap() -\u0026gt; devintr()\ninterrupt just means the state of device is changed\nthe bottom-half of interrupt doesn\u0026rsquo;t run in the context of top-half\nregisters: sie(supervisor interrupt enabled), PLIC claim: get next IRQ, sstatus\nkernelvec is like trampoline for kernel\nexecuting syscall in kernel, save in some proc\u0026rsquo;s stack\nmultiple devices? deliver to different CPU or stay pending\ndisable interrupts? clear SIE, using intr_off(), remember the pending interrupts, deliver when kernel re-enables interrupts\nmany places has parallelism, the operation msy not atomic!\nusing producer-consumer buffer\ntrampoline cannot tolerate a second interrupt to trampoline!\npolling strategy: Top-half loops until device says it is ready\nuse DMA is more efficient\nBook Chapter 5 dispatch happens in devintr()\ntop-half: kernel thread, bottom-kernel: executes at interrupt time\nUART appears as a series of memory-mapped registers\nuse consoleinit() to init UART hardware\ntransmit complete\ninit() will let the shell read the console\nread() -\u0026gt; consoleread() -\u0026gt; sleep()\ndevintr() -(UART)-\u0026gt; uartintr() -\u0026gt; consoleintr()\neach time the UART finishes sending a byte, it generates an interrupt.\nin write(), uartintr() -\u0026gt; uartstart()\nallowing processes to execute concurrently with device I/O\nin RISC-V, timer interrupt happens in M mode\nstart.c executes before main, to program CLINT hardware, set up a scratch area, set mtvec to timeervec\nThe kernel could be made somewhat simpler if device and timer interrupts only occurred while executing user code.\nLecture 9 save, process, resume\nasynchronous, concurrency, program devices\nHow the \u0026lsquo;$\u0026rsquo; appears, and what happens after ls ?\nPLIC: 53 interrupt connect from devices\ncore hold interrupt\nDriver manages device\ninterrupt handler: top, bottom, a queue in it with read/write interface\nthe queue is used to decouple top \u0026amp; bottom\nprogramming device: memory-mapped I/O; ld/st\nthe kernel and the device should make a protocol\n$: device put it into UART, UART gen interrupts when the char has been sent\nls: keyboard connect to receive line, generate interrupt\nRISC-V support:\nSIE: 1 bit for external interrupt\nSSTATUS: bit enable/disable\nSIP: interrupt pending\nSCAUSE: the cause of interrupt\nSTVEC: holds address for the switching\nplicinit(): take interrupt from the devices\nmore initialization in main.c, main() finally calls scheduler()\ninit.c: creates a device as console\nshell itself writes into fd 2\na pointer to producer and a pointer to consumer\nInterrupt:\nIf SIE bitset: clear SIE bits\nsepc\u0026lt;-pc, save current mode, entering supervisor mode, pc\u0026lt;-stvec\ninterrupts \u0026amp; concurrency:\ndevices \u0026amp; CPU run in parallel, interrupt stops current program\ntop \u0026amp; bottom deliver may run in parallel\nproducer \u0026amp; consumer: read after write, using a queue\nonce, interrupt was fast, now, interrupt is slow.\nsolution: polling dynamic switch\n","date":"2025-01-16T23:24:27+08:00","permalink":"https://vzstless.moe/p/xv6-lecture9/","title":"xv6 LECTURE9"},{"content":"基础 asm是一个GNU C扩展语法的关键词，当想使用ANSI C进行编译的时候使用__asm__代替asm\nC++中默认拥有asm关键字，而当编译时使用 -fno-asm flag 时应当使用__asm__进行内联汇编操作\nasm默认拥有volatile属性，使用inline修饰时编译器会尝试缩小asm的编译结果占用\n编译器不进行asm的token分析，为在一个asm语句中分多句汇编进行书写可采用\\n\\t分割\n有些特殊的汇编语言也可采用;进行分割\n使用方法 使用goto进行修饰时表名汇编可能进行地址跳转\n1 2 3 4 5 6 7 8 9 10 int src = 1; int dst; //copy src to dst and add 1 to dst asm (\u0026#34;mov %1, %0\\n\\t\u0026#34; \u0026#34;add $1, %0\u0026#34; : \u0026#34;=r\u0026#34; (dst) : \u0026#34;r\u0026#34; (src)); printf(\u0026#34;%d\\n\u0026#34;, dst); //dst = 2 gcc会在发现不需要汇编代码输出的时候忽视asm，同理，在for循环总是输出相同结果时拆循环优化\n特殊的，i386汇编在进行断言检测时无法被忽略\n使用volatile可以避免这种优化保证代码在优化下依然照常执行\n手动加入变量依赖也可以避免优化\nasmSymbolicName可以让内联汇编代码可读性更强\nFlagOutput用于进行比较\n为防止覆写，asm设置了clobber register，可在asm中随意使用\ncc: flag覆写\nmemory: 内存读写\nredzone: 汇编代码会写入红区\n1 2 3 4 // *z++ = *x++ * *y++ asm (\u0026#34;vecmul %0, %1, %2\u0026#34; : \u0026#34;+r\u0026#34; (z), \u0026#34;+r\u0026#34; (x), \u0026#34;+r\u0026#34; (y), \u0026#34;=m\u0026#34; (*z) : \u0026#34;m\u0026#34; (*x), \u0026#34;m\u0026#34; (*y)); 1 2 3 4 5 6 7 8 9 10 11 12 13 //an example of asm goto asm goto ( \u0026#34;btl %1, %0\\n\\t\u0026#34; \u0026#34;jc %l2\u0026#34; : /* No outputs. */ : \u0026#34;r\u0026#34; (p1), \u0026#34;r\u0026#34; (p2) : \u0026#34;cc\u0026#34; : carry); return 0; carry: return 1; OperandModifier: 通用类型：\nc: constant; cc: stronger %c; n: %c that expects value negated; a: memory reference; l: label printing\n（相关的专用寄存器见官方文档）\n更名 1 2 3 4 //变量更名 int foo asm(\u0026#34;myfoo\u0026#34;) = 2 //函数更名 int func(int x, int y) asm (\u0026#34;MYFUNC\u0026#34;); 寄存器关联 与全局寄存器关联\n1 register int *foo asm (\u0026#34;r12\u0026#34;); 空间占用 不保证过长的跳转或在汇编宏过大时不进行优化处理\nReference GCC assembly","date":"2025-01-16T08:15:22+08:00","permalink":"https://vzstless.moe/p/asm-in-c/","title":"ASM in C"},{"content":"Handout 8 pgtbl is hard to debug, why?\nhow to speed up syscall? Linux has vDSO\nvDSO enables virtual syscalls\n511: trampoline\n510: trapframe\n509: USYSCALL\nprotection bits? URV, WRV, XRV\nscan all pages could be expensive!!\nSlides 8 which syscall could be sped up?\nmo side-effect, return constant value, value can change after entering the kernel\noptions: getpid() \u0026amp; uptime()\nprovide a bitmask for pages accessed\ndetect page accesses without access bits? use page fault!\nTOCTOU attack: argument is modified after the kernel reads it\nchatgpt: reduce the time lap between check and use\nvirtual syscalls put syscalls access kernel space -\u0026gt; access process addr space, reduce the cost of context switching\nvDSO? a library, or a memory region\nvDSO is a fully formed ELF image\nList Balancing file-backed pages\nchange of kernel-tracking infrastructure\n","date":"2025-01-15T10:29:46+08:00","permalink":"https://vzstless.moe/p/xv6-lecture8/","title":"xv6 LECTURE8"},{"content":"Handout 7 VM-related projects: COW, mappings, performance\nideas: isolation, indirection\npanic? update page tables when page fault happens\nVA causes page fault: stval reg\nviolation causes page fault: scause reg\ninstruction/mode can also cause page fault\nif the user program asks for more memory, sbrk() could be expensive\nzero-filled page? large part of memory filled with zero\nCOW or write then copy\ndon\u0026rsquo;t let fork() copy every pages from parent\nbut share addr space between parent and child, use RSW in PTEs\npage fault: make copy, map, read/write(hard in real life!)\nload the pages for the file on demand\nkeep meta information in VMA\nmemory-mapping: use load \u0026amp; store to access files\npage-in \u0026amp; page-out due to the LRU strategy, especially when the file is larger than the VM page\nKPTI is used to handle meltdown\nSlides Modern OSes allocate memory lazily, only allocate memory when user program accesses the memory\nCOW: make all pages read-only, On page fault, copy page and mark R/W, use extra PTE bits\nBook Chapter 4.6 xv6\u0026rsquo;s response:\nkill the faulting process; kernel panic\nlet child and parent use same block of PM? overwritten!!! load, store, instruction page faults\nCOW fork is faster especially in fork just before exec\nlazy allocation\ndemand paging; page to disk\nThe Paper of COW https://lwn.net/Articles/849638/ Project Zero issue; CVE-2020-29374\nfor performance, android doesn\u0026rsquo;t put an exec() just behind fork()\nXu: Breaking COW by GUP; Tovalds: do_wp_pages()\nthe new approach breaks RDMA self-tests\na userfaultfd() was reported\nsomething about the new rules\nthe way of using RDMA for soft-dirty or userfaultfd() is broken now\nLecture 7 page faults can let page mapping from a static map to a dynamic one\ninformation needed: faulted va page, stval register\ntype of page fault\nwhen page fault happens:\nallocate 1 page, set the page all 0, map the page, restart instruction\nwhat if the process uses up the PM? just kill the process\nlazy allocation: the memory not allocated will not be mapped\nfree the memory that is not allocated will cause a fault, as the sbrk() let p-\u0026gt;sz go upper\nnegative number? shrinking addr space, but be careful!!!\nzero-fill on demand\nkalloc() a zero page, change the mapping\ncopy, update, restart\nthe cost of switching space and storing registers will be huge!!!\nCOW fork: use share instead of copy\nset all pages read only, receive page fault, copy the page into a new page, map it, restart instruction, call userret()\nexcept trampoline which could never be freed, other physical memory blocks are belonged to two or more different processes\nbut when to free the page?\ndemand paging\nexec(): load text, data, segment, eagerly alloc page\nread, map, restart\nIf out of memory: evict, use the just-free-page, restart\nevict the clean pages not dirty ones!!!\nmmap(va, len, plot, flags, fd, off)\nunmap(va, len), write back dirty block\n","date":"2025-01-14T12:07:31+08:00","permalink":"https://vzstless.moe/p/xv6-lecture7/","title":"xv6 LECTURE7"},{"content":"并查集 合并优化与路径压缩\n初始化：每个点属于独立的集\n合并，查找，统计集的个数\n例：hdu1213，直接使用并查集模板即可\n合并优化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 int height[N]; void init_set() { for(int i = 1; i \u0026lt;= N; i++) { s[i] = i; height[i] = 0; } } void merge_set(int x, int y) { x = find_set(x); y = find_set(y); if(height[x] == height[y]) { height[x] = height[x] + 1; s[y] = x; } else { if(height[x] \u0026lt; height[y]) s[x] = y; else s[y] = x; } } 路径压缩：在返回时将i所属的集全部归到根节点\n1 2 3 4 5 int find_set(int x) { if(x != s[x]) s[x] = find(s[x]); return s[x]; } 例：hdu3038，直接将序列抽象为并查集；\npoj1182，d(A-\u0026gt;C) = (d(A-\u0026gt;B) + d(B-\u0026gt;C)) % 3\n树状数组 树状数组和线段树的共同目的是在动态数组中维护前缀和\n节点上tree[]的值为树下直连子节点之和\nlowbit(x)=x\u0026amp;-x，用于找出二进制中的最后一个1\ntree[x]存储的是区间上\n简单应用：单点修改+区间查询\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 1000; #define lowbit(x) ((x) \u0026amp; - (x)) int tree[N] = {0}; void update(int x, int d) { while(x \u0026lt;= N) { tree[x] += d; x += lowbit(x); } } int sum(int x) { int ans = 0; while(x \u0026gt; 0) { ans += tree[x]; x -= lowbit(x); } return ans; } int a[11] = {0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13}; int main() { for(int i = 1; i \u0026lt;= 10; i++) update(a[i]); cout \u0026lt;\u0026lt; \u0026#34;old: [5, 8]=\u0026#34; \u0026lt;\u0026lt; sum(8) - sum(4) \u0026lt;\u0026lt; endl; update(5, 100); cout \u0026lt;\u0026lt; \u0026#34;new: [5, 8]=\u0026#34; \u0026lt;\u0026lt; sum(8) - sum(4) \u0026lt;\u0026lt; endl; return 0; } 使用update()初始化数组元素，使用sum()计算前缀和，修改元素，时间复杂度均为log(2n)\n例：hdu1556，使用树状数组进行单点修改反而会增加复杂度，应当将单点修改改为区间修改\n使用差分数组可进行区间修改\n对差分数组D进行如下操作：\nD[L] + d D[R+1] - d 使用差分数组前缀和进行求和操作 例：洛谷P3372，区间修改+区间查询，使用二阶树状数组 a1+a2+...+ak = kΣDi - Σ(i-1)Di 求前缀和使用两个树状数组处理 树状数组的扩展应用：\n二维区间修改+区间查询\n例：洛谷P4514，结合二维差分数组进行二维区间修改\n对于偏序问题有两种解法，归并排序和树状数组，归并排序需要多次复制数组，比树状数组慢一点\n例：洛谷P1908\n把数字看作数组的下标，每处理一个数字，树状数组的下表对应元素就+1，统计前缀和即可得到逆序对数量\n当数字过多时应使用离散化处理\n区间最值：也可使用树状数组进行求解，但是使用线段树等更加高效，例：hdu1754\n离线处理：先读取所有的查询，然后统一处理，计算结束后统一输出\n线段树 线段树用于解决区间最值问题和区间和问题\n线段树上的节点是“区间”\n对于线段树有：左右子树各一半，叶子节点只有一个元素，非叶子节点有多个元素，L=R时为叶子节点，L \u0026lt; R时为非叶子节点，左叶为[L, M]，右叶子为[M+1, R]，M=(L+R)/2\n线段树适合解的问题：大区间的解可以从小区间中的解合并而来\n线段树的定义：\n1 2 3 4 5 6 7 8 9 //第一种 struct { int L, R, data; }tree[N * 4]; //第二种 int tree[N * 4]; int ls(int p){return p \u0026lt;\u0026lt; 1;} int rs(int p){return p \u0026gt;\u0026gt; 1;} 二叉树的本质推导可得N个元素的线段树至少需要4N的空间才能装下\n线段树的构造：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 void push_up(int p) { tree[p] = tree[ls(p)] + tree[rs(p)]; //区间和 tree[p] = min(tree[ls(p)], tree[rs(p)]) // 求最小值 } void build(int p, int pl, int pr) { //节点编号与指向区间 if(pl == pr) { tree[p] = a[pl]; return; } int mid = (pl + pr) \u0026gt;\u0026gt; 1; build(ls(p), pl, mid); build(rs(p), mid + 1, pr); push_up(p); } 区间查询与lazy-tag相关 (TODO)\n","date":"2025-01-13T14:20:50+08:00","permalink":"https://vzstless.moe/p/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E7%AC%AC%E5%9B%9B%E7%AB%A0%E7%AC%94%E8%AE%B0/","title":"《算法竞赛》第四章笔记"},{"content":"Handout 6 focusing on user-\u0026gt;kernel transition\nNEVER execute user code in supervisor mode\nC on RISC-V puts function arguments in a0, a1, a2, \u0026amp;c\ncheck pagetables: C-a c, info mem\ntrampoline: the start of kernel\u0026rsquo;s trap handling code\nat the top: avoid punch a hole in user addr\nobserve PC is an indirect way to check whether we\u0026rsquo;re in supervisor mode\necall:\nchange mode, save PC in SEPC, jump to STVEC, disable further interrupts\necall does as little as possible\neven supervisor mode is constrained to use pgtbl\nsave the user registers:\nusing trapframe or the sscratch register\nwhy not a crash? we just switched page tables while executing\nthe trampoline is mapped at the same addr in pgtbls\nback to usertrap(), return $ and space\nusertrapret()\nprepare for next transition\nuse sret instruction\ncomplex from isolation\nwhat if design for faster?\nBook Chapter 4 ecall \u0026amp; exception will cause a trap\nstvec: trap handler\nsepc: PC saver\nscause: cause of occurring a trap\nsscratch: avoid overwriting\nusertrap: determine the reason of trap\nusertrapret -\u0026gt; userret -\u0026gt; switch satp to user space -\u0026gt; load trapframe addr to a0 -\u0026gt; executes sret\nargint, argaddr, argfd retrieves n\u0026rsquo;th argument of integer, address or fd\nkernelvec: save regs, jump to kerneltrap, yield\nLecture 6 don\u0026rsquo;t let user code to interfere the transition between user and kernel code\nsupervisor: R/W control regs, satp, stvec, sepc, sscratch, use PTE/PTE_U\nwrite() -\u0026gt; ecall -(user-\u0026gt;kernel)-\u0026gt; uservec -\u0026gt; usertrap() -\u0026gt; syscall() \u0026lt;-\u0026gt; sys_write() -\u0026gt; usertrapret() -\u0026gt; userret()\nthe user code could only access memory with PTE_U flag\n(checking by C-a c, info mem)\ncsrrw? swaps a0 and special temp register\nlack of crash, the status of pc -\u0026gt; we\u0026rsquo;re in supervisor mode\nOS cares lot about performance, so ecall never forces you to do stack operations\nstruct trapframe stays in proc.h, using 32 slots to save registers\nwhen running shell, sscratch holds the pointer to trapframe\nsave? beware overwrite\nthe instructions not executed? we\u0026rsquo;re still in trampoline, where user VA = kernel VA\nwhat if switch to another process?\nwe could only switch pgtbl on trampoline\nsret? re-enables interrupts, setting the PC same as sepc, switching user mode\nwhat happens in UIE?\n","date":"2025-01-12T16:14:43+08:00","permalink":"https://vzstless.moe/p/xv6-lecture6/","title":"xv6 LECTURE6"},{"content":"GDB step: one line of code at a time, jumps into the function\nnext: jump over functions\nstepi, nexti: do same thing for asm code\ncontinue: run until next breakpoint\nfinish: runs until the function ends\nbreak: set a breakpoint\nwatch: stop whenever value changes\nx: prints the raw memory\nprint: prints the expression\ninfo registers: print value of registers\ninfo frame: prints current stack frame\nset: change value of a variable\nHandout 5 overwrite return address will cause an infinite loop\nCalling Conventions int in RISC-V is always 32-bit wide, while long is 32-bit wide in RV32 and 64-bit wide in RV64\nin RV64, int is sign-extended\nstruct: pass first 8 pointer-words into register\ntwice size as a pointer word: use an even-odd pair; more than twice: pass by reference\nLecture 5 since published, x86 adds 3 instructions per month\n1 2 .section .test .global sum_to definition of .test is at \u0026lt;defs.h\u0026gt;\nfocus: switch the layout window in gdb\ntmux: C-b c: new window\nC-b p \u0026amp; C-b n: switch between terminals\nC-b %: vertical split\nC-b \u0026ldquo;: horizontal split\nC-b o: jump between splited windows\napropos will display gdb built-in manual\ncaller: not preserved, callee: preserved\ns0-s11 is for? maybe to give compiler flexibility\nstack frame generated by calls\nsp-\u0026gt;bottom of the stack\nfp-\u0026gt;top of the current frame\ni frame: show the message of stack frame\nbacktrace\n","date":"2025-01-09T21:52:22+08:00","permalink":"https://vzstless.moe/p/xv6-lecture5/","title":"xv6 LECTURE5"},{"content":"Handout 4 what if a user program writes to a random part of memory?\nwhat way could we separate and isolate memory?\npage tables\na level of indirection: CPU -(VM)\u0026gt; MMU -(PM)\u0026gt; MEM\nsatp, MMU, kernel\nreduce the size of page tables, not building a direct-map\npage=4KB, maximum 52 bits, nowadays 27bits\npage table entry: 64 bits, 54 used, 10 of them are flags, low 12 bits of PA are from VA\n3-level page table to reduce its size\na tree descended 9 bits at a time\npage-fault forces transfer to kernel\nPHYSTOP = 0x88000000\nthe design and arrangement of user address space: easier for compiler to compile\nneed contingous PM not VM\nkvmmake() makes kernel\u0026rsquo;s page table\nkvmmap() adds PTEs to a page table\nBook Chapter 3 1 2 3 4 5 6 7 8 9 10 bits 25 27 12 VA EXT index offset | V bits 44 10 pagetable PPN flags | V bits 44 10 PA index offset TLB: avoid the cost of loading PTE\nwrite PA into satp register\n1 page table per process\nKERNBASE=0x80000000\nfork() uses parent\u0026rsquo;s virtual memory address directly\ntrampoline and kernel stack aren\u0026rsquo;t directly-mapped\npagetable_t: a pointer to root page table page\nwalk() looks up for PTE\u0026rsquo;s VA\ninstruction sfence.vma flushes CPU\u0026rsquo;s TLB\nallocator: keeps a free list of struct run\nkfree: set value to all 1\nrefuse to execute, occur a page fault, kill the process and print the message\nmake exploit attack harder by such a protection process\nsbrk() -\u0026gt; growproc() -\u0026gt; uvmalloc()/uvdemalloc() -\u0026gt; kalloc()/uvmunmap() exec() -\u0026gt; namei() -\u0026gt; quick check -\u0026gt; proc_pagetable() -\u0026gt; loadseg() -\u0026gt; walkaddr()\nxv6 is lack of malloc()-like allocator to allocate small pieces of space\nLecture 4 What do we want from isolation?\nThe VA_MAX could be larger than PA_MAX\nwhere does page table allocates? kalloc()\nthere are 4096 bytes of continuous PA in PM, but not continuous for pages\nthe size of PM is determined by designers\nsatp is points to the top directory\ndon\u0026rsquo;t use a translation scheme to rely on another translation scheme, so store PA in tables\nsatp also stores PA\nwhy walk() ? initialization, sysinfo() needs walk()\nflexibility stays in dealing with page faults\nwhere will the data store? depends on a \u0026ldquo;multiplexer\u0026rdquo;\nmostly-identity mapping is used in kernel mapping\nstack overflow: page fault instead of covering other program\u0026rsquo;s memory\nconsolidate the mapping? good, but xv6 didn\u0026rsquo;t do this action\n1 2 3 4 5 b main c b kvminit c layout src 1 2 b kvminithart c where to store satp? in each proc structure, there\u0026rsquo;s a satp\nwhy 3-level not a single big table? you can remain many blocks empty\netext is the last addr of kernel, KERNBASE=0x80000000, etext-KERNBASE=size of kernel\n","date":"2025-01-07T18:57:30+08:00","permalink":"https://vzstless.moe/p/xv6-lecture4/","title":"xv6 LECTURE4"},{"content":"BFS与DFS BFS = 队列，访问第i层节点时，第i层节点出队，第i+1层节点入队\nDFS = 递归\nDFS的常见操作：DFS时间戳，DFS序列二次输出，产生树的深度，产生子树节点总数\n先序遍历，中序遍历，后序遍历\nDFS框架：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ans; void dfs(层数, 其他参数){ if(出局判断){ 更新答案; return; } (剪枝) for(下一层可能的枚举情况) if(used[i] == 0){ used[i] = 1; dfs(层数+1, 其他参数); used[i] = 0; } return; } 对比：BFS可能耗费大量空间，DFS可能搜索大量无效节点，DFS适合用于寻找任意可行解，BFS适合用于寻找范围最优解，DFS代码量远小于BFS\nBFS常使用map和set进行去重，DFS常使用剪枝进行优化\n连通性判断 例：lanqiao178，遍历一个连通块，再遍历下一个连通块，直至遍历完所有的连通块，统计共有多少个连通块\nDFS：搜索周围所有的#，把搜索过的#进行标记，统计没有高地的岛屿数量\n剪枝 BFS判重：相同的点只处理一次\n例：lanqiao642，使用STL的map与set判重\n例：hdu1010: 奇偶判断，可行性剪枝\n先使用可行性：剪掉k\u0026gt;T, 剪掉tmp=T-k-(abs(c-x)+abs(d-y))\n奇偶剪枝：本题在tmp为奇数情况下必定无解\n使用曼哈顿距离判断两格是否可达\n优化搜索顺序，排除等效冗余\n洪水填充 从种子点出发在封闭区域内进行涂色\nDFS示例：\n1 2 3 4 5 6 7 8 9 10 11 void floodfill(int x, int y, int fillColor, int oldColor) { if(check(x, y) == true \u0026amp;\u0026amp; color(x, y) == oldColor) { setColor(x, y, fillColor); floodfill(x + 1, y, fillColor, oldColor); floodfill(x - 1, y, fillColor, oldColor); floodfill(x, y - 1, fillColor, oldColor); floodfill(x, y + 1, fillColor, oldColor); } } 时间、空间复杂度均为O(n^2)\nBFS最短路径 相邻两个点距离相等时使用BFS计算最短路径时间复杂度为O(m)\n例：lanqiao602，字典序D\u0026lt; L \u0026lt; R \u0026lt; U，使用BFS进行迷宫寻路\n标准方法：存储路径上每一个节点的前驱节点\n邻居节点间距离不同时应使用Dijkstra算法\n双向广搜 有确定的起点和终点，分别从起点和终点出发进行相遇\n下一层节点数增加越快，双向广搜效率改善越强\n一个队列为空之前，若相遇，则有解，若一个队列为空之后还没有相遇则无解\nBFS与优先队列 本质上是Dijkstra算法\n从起点开始逐层扩展邻居，扩展完成后弹出最小边权的边\n总复杂度为O((n+m)logn) 例：lanqiao1122\nBFS与双端队列 高效解决边权只可能是0或1的问题\n例：洛谷P4467 建模为最短路径问题，不需要旋转则边权为0，需要旋转则边权为1\n扩展边权为0的邻居点时看作同一层，从队头插入，边权为1的边扩展时看作下一层的点，从队尾插入\n起点放入队列，弹出队头，扩展直连邻居，重复以上过程直至队列为空\n不允许节点重复入队，没有排序过程，时间复杂度为O(n)\nA*算法 给定一个确定的起点与确定（或可预测）的终点，求起点到终点的最短路径\n贪心搜索：只看终点，不看起点，不回头重新选择，不能提前绕开障碍\nDijkstra：只管起点，不管终点，遍历几乎所有的点就可以得到最终的结果\nA*算法的核心：f(i)=g(i)+h(i)\n设路径为s-i-t，f(i)为对i的评估，g(i)为已经走过的路径，h(i)为从i到t的代价\n曼哈顿距离：只能朝四个方向进行移动\nh(i)=abs(i.x-t.x)+abs(i.y-t.y)\n对角线距离：只能在八个方向移动\nh(i)=max(abs(i.x-t.x), abs(i-y-t.y))\n欧氏距离：可以向任意方向移动\nh(i)=sqrt((i.x-t.x)^2 + (i.y-t.y)^2)\nIDDFS与IDA* IDDFS：限制层数的基础上进行DFS\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 bool IDDFS(s, t, max_depth) for depth from 0 to max_depth if(DFS(s, t, 0) == true) return true; return false; bool DFS(s, t, d) if(d \u0026gt; Depth) return false; if(s == t) return true; for each adjacent i of s if(DFS(i, t, d+1) == true) return true; return false; IDA*：在IDDFS基础上进行剪枝操作\n例：poj3134，使用估价函数进行剪枝\n","date":"2025-01-06T10:04:13+08:00","permalink":"https://vzstless.moe/p/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E7%AC%AC%E4%B8%89%E7%AB%A0%E7%AC%94%E8%AE%B0/","title":"《算法竞赛》第三章笔记"},{"content":"Handout 3 No OS: lack of isolation\nfork() -\u0026gt; abstract core\nexec()/sbrk() -\u0026gt; abstract RAM\nassumption: user is always willing to break the isolation, while kernel is always trustable\nuser mode and supervisor mode\npgtbl: maps virtual-\u0026gt;physical\necall: change to supervisor mode, get to a known point of the kernel code\nSingularity provides a way of process isolation without hardware support\nkernel is a big program holds all of the syscalls\nOn CVE there\u0026rsquo;s 2997 bugs detected on Linux in 2024(kernel bugs are much more common than we thought)\nbuild the kernel: make\ngcc compiles every .c, .o, linking, kernel/kernel, kernel/kernel.asm, produces an .iso\nrun the OS: make qemu\nsimulates the CPU, run into the first instruction in the OS\nkernel/entry.S -\u0026gt; start.c -\u0026gt; main()\nBook Chapter 2 Isolation can be done by protecting sensitive hardware from system calls\nmonolithic kernel: the whole OS resides in the kernel\nmicro kernel: minimalize code run in the supervisor mode\nin xv6, isolation is done by setting processes\ntrampoline: contains the code from user space to kernel space\ntrapframe: protects the status of the process\nsret instruction is used to return to user space from kernel space\nprocess: an addr space as a virtual RAM and an thread as a virtual CPU\nBoot a RISC-V Computer:\npower on -\u0026gt; run bootloader -\u0026gt; load kernel into memory address 0x80000000(I/O starts from here) and run into M mode -\u0026gt; set up a stack at _entry for runnning C code -\u0026gt; run into start of C -\u0026gt; program the clock chip to generate timer interrupts -\u0026gt; call useerinit to start the first syscall -\u0026gt; complete exec() -\u0026gt; return to user space and initialize the shell\nLecture 3 No strong isolation will cause memory overwrite, which will lead to a bug hard to debug\nOS should be defensive\nThere is a flag to check whether the CPU is at user mode or kernel mode\nBIOS is always trustworthy\nfork() as a syscall hasn\u0026rsquo;t its function decalaration\nwhen calling fork: ecall sys_fork (here sys_fork is a number) -\u0026gt; syscall -\u0026gt; find number in a0 -\u0026gt; create a new process\nHow to get control from buggy useer application? set a timer\nthink qemu as a real circuit board\nqemu is an infinite for loop: fetch, decode, execute\nuse gdb: b _entry; c; si; layout src;\nuse n to goto next line of C code\nBook Chapter 4.3 \u0026amp; 4.4 (Before the labs\u0026hellip;)\nargs for exec() in a0 \u0026amp; a1, syscall number in a7\nSYS_exec -\u0026gt; sys_exec\nreturn value in p-\u0026gt;trapframe-\u0026gt;a0\nfetchstr -\u0026gt; copyinstr -\u0026gt; walkaddr -\u0026gt; walk -\u0026gt; pagetable\nJust before Lab syscall\u0026hellip; installing riscv64-unknown-elf-gdb:\ndownload the tar file from TUNA mirror site, unpack it, enter the current directory\n1 2 3 4 5 mkdir build cd build ../configure --prefix=/usr/local --target=riscv64-unknown-elf make -j 12 sudo make install using gdb 1 2 3 4 5 target remote localhost:26000 b syscall c layout src backtrace 1 2 p /x *p p /x $sstatus ","date":"2025-01-05T09:49:10+08:00","permalink":"https://vzstless.moe/p/xv6-lecture3/","title":"xv6 LECTURE3"},{"content":"Handout 2 memory layout:\ntext: code, read-only data\ndata: global C vars\nstack: local variables\nheap: sbrk, malloc, free\n.c -compile-\u0026gt; .o -link-\u0026gt; executable file\nstrlen() uses array access while strcmp() uses pointer access\nkalloc() keeps a large linked list of free pages of memory\nLRU buffer cache is implemented as a dual-pointer linked list\nstatic: limited to the file where the variable is declared\nSlides This class focus on RAM and I/O\naddress space: represent bus as a giant array of data\nmemory allocation: decide where array to store things\nA stack is much more smaller than heap\nK\u0026amp;R alloc: use a stack to allocate memory space\nafree: pop the space and decrease the pointer\nthe behavior is undefined for arithmetic or comparisons with pointers that do not point to members of the same array\nsize_t is uint returned by sizeof()\nthe result of modifying the string pointer is undefined\n","date":"2025-01-03T22:12:02+08:00","permalink":"https://vzstless.moe/p/xv6-lecture2/","title":"xv6 LECTURE2"},{"content":"尺取法 反向 1 for(int i = 0, j = n - 1; j \u0026gt; i; i++, j--){} 同向 例：寻找区间和：输入正整数n，数组a，正整数s，输出所有可能的a中两数字加和等于n的情况\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; int a[1000]; void findsum(int *a, int n, int s) { int i = 0, j = 0; int sum = a[0]; while(j \u0026lt; n) { if(sum \u0026gt;= s) { if(sum == s) printf(\u0026#34;%d %d\\n\u0026#34;, i, j); sum -= a[i]; i++; if(i \u0026gt; j) { sum = a[i]; j++; } } if(sum \u0026lt; s) {j++; sum += a[j];} } } int main() { int n; cin \u0026gt;\u0026gt; n; for(int i = 0; i \u0026lt; n; i++) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;a[i]); } int s; cin \u0026gt;\u0026gt; s; findsum(a, n, s); return 0; } 多指针 两个指针不够用时使用多指针进行优化\n例：给出一串数及数字C，要求计算出所有符合A-B=C的数对有几对（不同位置的相同数值看作两个数字）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include\u0026lt;bits/stdc++.h\u0026gt; #define ll long long using namespace std; const int N = 2e5 + 5; int a[N]; int main() { int n, c; cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; c; for(int i = 1; i \u0026lt;= n; i++) cin \u0026gt;\u0026gt; a[i]; sort(a + 1, a + 1 + n); ll ans = 0; for(int i = 1, j = 1, k = 1; i \u0026lt;= n; i++) { while(j \u0026lt;= n \u0026amp;\u0026amp; a[j] - a[i] \u0026lt; c) j++; while(k \u0026lt;= n \u0026amp;\u0026amp; a[k] - a[i] \u0026lt;= c) k++; if(a[j] - a[i] == c \u0026amp;\u0026amp; a[k - 1] - a[i] == c \u0026amp;\u0026amp; k - 1 \u0026gt;= 1) ans += k - j; } cout \u0026lt;\u0026lt; ans; return 0; } 二分法 一般的二分查找\n1 2 3 4 5 6 7 8 9 10 11 int bin_search(int *a, int n, int x) { int left = 0, right = n; while(left \u0026lt; right) { int mid = (left + right) / 2; if(a[mid] \u0026gt;= x) right = mid; else left = mid + 1; } return left; } 整数二分法的典例：最大值最小化和最小值最大化\n例：洛谷P1824（我甚至花了半个小时才看懂这道题要求啥），使用贪心法时间复杂度为平方，发现dis有上下界，可以使用二分法求解，时间复杂度为O(nlogn)\n实数范围的二分法：没有取整问题，只需要验证right - left \u0026gt; eps即可\n实数二分例题：POJ 3122\n三分法：缩小区间可使用三等分法（mid1和mid2均为三等分点）与近似三等分法（算中点，然后±eps算出mid1和mid2）\n例题：洛谷P3745\n倍增法 例题：洛谷P4155，同时涉及化圆为线，贪心法，二分法，倍增法\n这里定义go[s][i]为从第s个区间出发，走2^i个最优区间后到达的区间\ngo[s][i] = go[go[s][i-1]][i-1]\n从s起跳，先跳2^(i-1)步到达z=go[s][i-1]\ngo[go[s][i-1]][i-1]=go[z][i-1]，再从z跳2^(i-1)步到区间go[z][i-1]\nST算法：最值查询问题\n原理：一个大区间若能被两个小区间覆盖，那么大区间的最值等于两个小区间的最值\n定义dp[s][k] = min(dp[s][k-1], dp[s+1\u0026laquo;(k-1)][k-1])\n例题：洛谷P2880\n前缀和与差分 一维 sum[n] = Σ(a[0]~a[n])\n差分是前缀和的逆运算\n例题：hdu 1556\n二维 D[i][j]=a[i][j]-a[i-1][j]-a[i][j-1]+a[i-1][j-1]\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; int D[5000][5000]; int main() { int n, m; scanf(\u0026#34;%d%d\u0026#34;, \u0026amp;n, \u0026amp;m); while(m--) { int x1, x2, y1, y2; scanf(\u0026#34;%d%d%d%d\u0026#34;, \u0026amp;x1, \u0026amp;y1, \u0026amp;x2, \u0026amp;y2); D[x1][y1] += 1; D[x2+1][y1] -= 1; D[x1][y2+1] -= 1; D[x2+1][y2+1] += 1; } for(int i = 1; i \u0026lt;= n; ++i) { for(int j = 1; j \u0026lt;= n; ++j) { D[i][j] += D[i-1][j] + D[i][j-1] - D[i-1][j-1]; printf(\u0026#34;%d \u0026#34;, D[i][j]); } printf(\u0026#34;\\n\u0026#34;); } return 0; } 三维 建议直接求前缀和，不写递推公式\n1 2 3 4 5 6 7 8 D[x1][y1][z1] += d; D[x2 + 1][y1][z1] -= d; D[x1][y1][z2 + 1] -= d; D[x2 + 1][y1][z2 + 1] += d; D[x1][y2 + 1][z1] -= d; D[x2 + 1][y2 + 1][z1] += d; D[x1][y2 + 1][z2 + 1] += d; D[x2 + 1][y2 + 1][z2 + 1] -= d; 离散化 用数字的相对值取代它们的绝对值\n离散化：排序，离散化，归位\nSTL中的lower_bound()和unique()可实现离散化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 500010; int olda[N]; int newa[N]; int main() { int n; scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); for(int i = 1; i \u0026lt;= n; i++) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;olda[i]); newa[i], olda[i]; } sort(olda + 1, olda + 1 + n); int cnt = n; //cnt = unique(olda + 1, olda + 1 + n) - (olda + 1); for(int i = 1; i \u0026lt;= cnt; i++) { newa[i] = lower_bound(olda + 1, olda + 1 + n, newa[i]) - olda; } for(int i = 1; i \u0026lt;= cnt; i++) { printf(\u0026#34;%d\u0026#34;, newa[i]); } printf(\u0026#34;\\n cnt = %d\u0026#34;, cnt); return 0; } 排序与排列 排序略\n排列：next_permutation()只输出比自己大的排列，排序范围同sort()\n1 2 3 4 5 6 7 8 9 10 11 12 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; int main() { string test = \u0026#34;abcd\u0026#34;; sort(test.begin(), test.end()); do { cout \u0026lt;\u0026lt; test \u0026lt;\u0026lt; endl; }while(next_permutation(test.begin(), test.end())); return 0; } 自写全排列基于DFS\n分治法 将大问题分解为k个规模类似的小问题\n例：汉诺塔\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; int sum = 0, m; void hanoi(char x, char y, char z, int n) { if(n == 1) { sum++; if(sum == m) cout \u0026lt;\u0026lt; \u0026#34;#\u0026#34; \u0026lt;\u0026lt; n \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34;-\u0026gt;\u0026#34; \u0026lt;\u0026lt; z \u0026lt;\u0026lt; endl; } else { hanoi(x, z, y, n - 1); sum++; if(sum == m) cout \u0026lt;\u0026lt; \u0026#34;#\u0026#34; \u0026lt;\u0026lt; n \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34;-\u0026gt;\u0026#34; \u0026lt;\u0026lt; z \u0026lt;\u0026lt; endl; hanoi(y, x, z, n - 1); } } int main() { int n; cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; m; hanoi(\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, n); cout \u0026lt;\u0026lt; sum \u0026lt;\u0026lt; endl; return 0; } 逆序对问题：树状数组或者归并排序，归并排序需要大量复制数组，比树状数组慢一点儿\n例：hdu4911\n对逆序对的观察：在子序列内部，元素都是有序的，逆序对只存在于不同的子序列之间\n合并两个子序列时，如果前一个子序列元素比后一个小，则不产生逆序对，反之则产生\n交换不超过k次，统计逆序对数量，cnt\u0026lt;=k则最少逆序对数量为0，若cnt\u0026gt;k则让k次交换都发生在相邻数上，逆序对为cnt-k\ncnt+=mid-i+1\n快速排序：将序列分为左右两部分，使左边的数字都小于右边的，递归这个过程直至无法再分为止\n快速排序可用于解决第k大数问题，例：poj2388\n贪心法与拟阵 例：最少硬币问题\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int n = 3; int coin[] = {1, 2, 5}; int main() { int i, money; int ans[n] = {0}; cin \u0026gt;\u0026gt; money; for(i = n - 1; i \u0026gt;= 0; i--) { ans[i] = money / coin[i]; money = money - ans[i] - coin[i]; } for(i = n - 1; i \u0026gt;= 0; i--) cout \u0026lt;\u0026lt; coin[i] \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; ans[i] \u0026lt;\u0026lt; endl; return 0; } 但是贪心法有时会无法解出最少硬币问题，无法解时应使用动态规划\n贪心算法问题应当满足最优子结构和贪心选择两条性质\n如果一个问题能够构造为拟阵，那么这个问题即可使用贪心算法进行求解\n","date":"2025-01-02T16:43:11+08:00","permalink":"https://vzstless.moe/p/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E7%AC%AC%E4%BA%8C%E7%AB%A0%E7%AC%94%E8%AE%B0/","title":"《算法竞赛》第二章笔记"},{"content":"Handout 1 Purpose of an OS:\nIsolate hard/software, virtualize hardware\nInteract with OS via syscalls\nFirst arg in syscall is FD\nUNIX I/O is 8-bit bytes\nWhen CPU receives a syscall:\nsave, jump, execute, call, restore, reduce, jump back\nShell is a user program instead of shell\nfork() lets us create a new process\nexec() replaces current process with an executable file\nBook Chapter 1 Operating system let different softwares use hardware together\nProcess: instructions, data, stack\nfork() returns 0 in the child process while pid in the parent process\nwait() returns the pid and copies the exit status\nexec() loads a file and executes it\nfile descripter refers to a file.\nfork() and exec()let the shell has the chance to redirect child\u0026rsquo;s I/O\nFile descripter is a good abstraction\nPipe is a small kernel buffer conncting files.\nPipe: auto-clean, pass long data, allow parallel execution\nUnderlying file is called inode\ncd is built-in, if not, the shell will form a infinity process tree of dir-changing\nALL XV6 PROGRAMS RUN AS ROOT!!!!!\nAmusement: UNIX In order to avoid large amount of team population and project cost, we need to build a good programming environment. UNIX is for building such an environment.\nPROBLEM: Large number of softwares, large scale of jobs\nSoftware is always demanded for different operations, to avoid rewrite code per annum, the code should be divided into modules. Layers: kernel, shell, util\nA show of pipes\nEasy and packed pattern-matching algorithms\nRefer file as a simple sequence of bytes, file is contained in directories\nConcept of I/O redirection\nC: If you need to avoid hardware, simply use it; but also ways to interact with hardware directly\nAn example of a software, inputting boolean equation and outputting circuit traces\nComputer is built for easy to use\nLecture 1 What would a kernel do?\nEveryone thought OS provides what they already know\nMany tensions occurred in OS design\nFunc call vs Syscall? func hasn\u0026rsquo;t previlege to access real CPU and mem but syscalls have\nHigh-level language is designed to be portable\nThere is a rule that we read from fd 0 and write to fd 1\nKernel holds a process table and guided by fd\nInstruction ecall passes the system from user space to the kernel space\nParent and child process shares the same fd\nexec() loads the program in the file and throw away current process\nexec() remains the fd that already exists\nwait() waits the child process to return, if the process hasn\u0026rsquo;t child process, it\u0026rsquo;ll return -1\nJust before Lab util\u0026hellip; installing the riscv64-unknown-elf-gcc:\n1 sudo apt install gcc=riscv64-unknown-elf ","date":"2025-01-01T08:28:39+08:00","permalink":"https://vzstless.moe/p/xv6-lecture1/","title":"xv6 LECTURE1"},{"content":"理论上一个计算机都快学不明白的人不应该对外行的见识发表暴论，但既然学校选择了力推外专业“选修”，不修毕不了业，那我就不先礼后兵了\n许多人现如今已经不太看重所谓的MBA或者别的类似的商学学位，认为它们纯纯是二水货，事实证明他们没错。商学的死不是因为商学被什么别的哲学取代了，而是商学被计算机从思维意义上被取代了。这时候你大概率要问：是计算机代替了人力参与了商学相关的事务了吗？是也不是，因为不只是人类意义上的代替，还有思想层面的代替。\n几乎所有的管理学相关的思想在计算机哲学中都能找到代替品，而且研究层面上更加极端。流水线优化与对节拍异化为了CPU流水线性能优化，工作中心分配异化为了操作系统中的线程调度优化，公交线路布局异化为了找最长路径，观察次数异化为了单纯的统计题，工序优化异化为了对一个有向图进行拓扑排序，至于剩下的，大概率交给Excel或者大模型都可以完成。从思想和实践层面，计算机科学都直接毙掉了商学。\n也许商学的下一步应该把UNIX编程艺术列为必读书目？但总之不应该是罗宾斯管理学这种老东西了。\n","date":"2024-12-30T08:08:50+08:00","permalink":"https://vzstless.moe/p/%E5%95%86%E5%AD%A6%E7%9A%84%E6%AD%BB%E4%BA%A1/","title":"商学的死亡"},{"content":"（一篇在分享会上的稿件的留档）\n引子 Mathematica的基础语法三句话就能解决：\n1.内置函数的每个单词以大写字母开头。\n2.函数用[]传参。\n3.List用{}包围。\n1 2 {1，2，3} {{1，2}，{3，4}} 由于Mathematica的语法糖实在是太多太多太多了，所以这里我尽量使用最基础的语法。可能看着不好看，但是保看懂。（Mathematica不带转义md的功能，所以这个文档的代码显示并不好）\n这个问题来自于10年前百度贴吧Mathematica吧的一个帖子，我们尝试复现一下这个问题。\n生成方程并提取方程的解 系数为±1的二次方程长这样：\n1 2 3 4 In[]:=x^Range[0, 2] . # == 0 \u0026amp; /@ Tuples[{-1, 1}, 3] Out[]={-1 - x - x^2 == 0, -1 - x + x^2 == 0, -1 + x - x^2 == 0, -1 + x + x^2 == 0, 1 - x - x^2 == 0, 1 - x + x^2 == 0, 1 + x - x^2 == 0, 1 + x + x^2 == 0} In和Out代表运行语句和运行结果，不用管它们。你只需要看Out后头生成的东西。这里使用的生成方法是穷举-1和1的n+1元组合与x的从0到n次幂点乘等于0。但是这个方法有点儿慢，用代数数可以快点儿。\n1 2 In[]:=AlgebraicNumber[x, {1, -1, 1, 1, -1}] == 0 Out[]=1 - x + x^2 + x^3 - x^4 == 0 严格来说，Mathematica内部的代数数函数是有点儿问题的，因为它允许系数取实数范围，不过这不重要，重点是我们生成了一个符合题干要求的方程，而且这个语法比上头那个好使一万倍。\n接下来，解方程。先想到的肯定是NSolve，Solve用于求某个方程的解析解，NSolve用于求某个方程的数值解。\n1 2 In[]:=NSolve[AlgebraicNumber[x, {1, -1, 1}] == 0, x] Out[]={{x -\u0026gt; 0.5 - 0.866025 I}, {x -\u0026gt; 0.5 + 0.866025 I}} 画图肯定不能指望这玩意儿画，所以要想办法提取出来解。用TreeForm分析层次（或者瞪眼法也行）可知，第一层是包含两个List的List，第二层是包含每个解的List，第三层是-\u0026gt;（Mathematica中称为Rule）。[[]]可以用来提取解，而ReIm函数可以将解的实部和虚部生成一个List返回。\n1 2 In[]:=ReIm[NSolve[AlgebraicNumber[x, {1, -1, 1}] == 0, x][[All, 1, 2]]] Out[]={{0.5, -0.866025}, {0.5, 0.866025}} 尝试画个图先\n1 In[]:=ListPlot[ReIm[NSolve[AlgebraicNumber[x, {#1, #2, #3, #4, #5, #6, #7, #8, #9, #10}] ==0, x][[All, 1, 2]]] \u0026amp; @@@ Tuples[{-1, 1}, 10]] 其中ListPlot为绘制散点图，@@@用于替换表达式的一级标头（TreeForm的第一层），#和\u0026amp;为纯函数的自变量和结尾标识，这个图长这样：\n然后你发现你的电脑有点儿卡了。\n效率问题 我们循规蹈矩一点儿，至少还有两招能用。\n1.小数比整数快。\n如果你在Mathematica计算1/2，结果会返回二分之一。同理的，解方程也会如此。\n1 2 3 4 In[]:=Solve[2 x^2 + 3 x + 4 == 0, x] Out[]={{x -\u0026gt; 1/4 (-3 - I Sqrt[23])}, {x -\u0026gt; 1/4 (-3 + I Sqrt[23])}} In[]:=Solve[2.0 x^2 + 3.0 x + 4.0 == 0.0, x] Out[]={{x -\u0026gt; -0.75 - 1.19896 I}, {x -\u0026gt; -0.75 + 1.19896 I}} Mathematica中整数的精度不是1，而是无穷。我们显然不需要那么高的精度，用机器精度足以完成任务了。\n2.专用函数比通用函数快。\nSolve和NSolve的求解原理是求f(x)=0的反函数，对于超越方程来说，没办法，只能是它。但是我们今天的主角是多项式，可以有更快的方法。\n1 2 In[]:= NRoots[AlgebraicNumber[x, {1, -1, 1}] == 0, x] Out[]=x == 0.5 - 0.866025 I || x == 0.5 + 0.866025 I NRoots给出一个多项式方程的数值近似解。\n验证一下NRoots和NSolve哪个更快,求解1000个方程比较一下。\n1 2 3 4 In[]:=AbsoluteTiming[Do[List@@NRoots[AlgebraicNumber[x, {4., 3., 2., 1.}] == 0, x][[All, 2]], {1000}]] Out[]={0.0411889, Null} In[]:=AbsoluteTiming[Do[List@@NRoots[AlgebraicNumber[x, {4., 3., 2., 1.}] == 0, x][[All, 1, 2]], {1000}]] Out[]={1.1734, Null} 一个0.04秒，一个1.17秒，差距相当明显。\n如法炮制，我们观察一下结构（或者使用TreeForm），第一层是Or，也就是||，第二层是用Equal（==）连接的x与对应解。开始替换。\n1 2 In[]:=ReIm[List @@ NRoots[AlgebraicNumber[x, {1, -1, 1}] == 0, x][[All, 2]]] Out[]={{0.5, -0.866025}, {0.5, 0.866025}} 理论上，只要把这玩意儿封装成函数，画个散点图这事儿就结束了。但是还是别这样了，我试过了，13次方程，用了65秒，全程内存占用没下700M。\n师夷长技以制夷 思考一个问题：我真的需要求出所有的方程的解吗？\nx^2+x+1==0和-x^2-x-1==0的解是一模一样的，之前生成的这些方程中有一半是求解了也没用的。所以我们只需要考虑最高次系数为正1的情形。\n1 f[list_]:=List@@NRoots[AlgebraicNumber[x,Append[list,1]]==0,x][[All,2]] Append用于在列表末尾插入值。\n再试试？\n1 2 In[]:=AbsoluteTiming[f /@ Tuples[{-1, 1}, 13]] Out[]={6.16429,{...}} 现在我们倒是求出来了13次方程的所有解，然而吧主的最终图像中求解了19次方程，这个时间是6.16秒的5个数量级，而且这还没计算画图时间。显然，这是我们承受不起的。\n然后，我们发现了一个悲哀的事实：\nMathematica中NRoots的求解效率比MATLAB中的roots低了一个数量级！\n幸运的是，MATLAB可以随意篡改函数的源代码，一句话就可以一睹这个函数的芳容：\n1 edit(which(\u0026#34;roots.m\u0026#34;)) 举例说明一下原理：\n$$ a_3x^3+a_2x^2+a_1x+a_0=0 $$$$ A=\\begin{bmatrix} -\\frac{a_2}{a_3} \u0026 -\\frac{a_1}{a_3} \u0026-\\frac{a_0}{a_3} \\\\ 1 \u0026 0 \u0026 0\\\\ 0 \u0026 1 \u0026 0 \\end{bmatrix} $$$$ x=\\begin{bmatrix} x_1\\\\x_2\\\\x_3 \\end{bmatrix} $$$$ \\begin{matrix} -\\frac{a_2}{a_3}x_1-\\frac{a_1}{a_3}x_2-\\frac{a_0}{a_3}x_3=\\lambda x_1\\\\ x_1=\\lambda x_2\\\\ x_2=\\lambda x_3 \\end{matrix} $$ 代入原方程就可以把求解方程的解转化为求解矩阵的特征值，以上原理对n次方程依然成立。\n明白了原理就可以自己写一个类似的，不过我们只要系数±1的情况所以不必完全照抄。\n1 2 3 4 modifiedroots[c_List]:=Module[{a},a=DiagonalMatrix[ConstantArray[1.,Length[c]-1],-1]; a[[1]]=-c; Eigenvalues[a] ]; （顺带一提Mathematica里头用个局部变量麻烦得可怕，同样可怕的是字符串拼接，不过今天的内容不涉及）\n算14次方程的时候这个函数竟然只用了1.23秒！（我们一共计算了2^14个方程）\n准备绘图。不过我们换个方式。前头的两个散点图太难看了，我们改成密度图。\n首先对点的分布进行统计。既然效率提高了就直接上18次方程。\n1 2 3 4 5 In[]:=n = 18; data = ReIm[Flatten[modifiedroots /@ Tuples[{-1, 1}, n]]]; counts = BinCounts[data, {-2, 2, 4./601}, {-2., 2., 4./601}]; Sort[Flatten[counts]] Out[]=(*这里的输出有多于36万个元素，不进行列举*) 将统计结果转化为平面直角坐标系中的对应点的灰度：\n1 ArrayPlot[counts] 大概长这样：\n合理的篡改 这个图并不好看，甚至于说没有观察价值。\n回到数据观察，我们发现这个数据集中有一大半的0和一大半1000以上的数据。光学的衍射实验中也有类似的情况，称为衍射主极大。我们平常在书上看到的衍射图样都是被处理过的，实际上，真正的衍射实验中中间的条纹光强是远高于边缘的小条纹的。\n1 2 In[]:=Sort[Flatten[UnitStep[300 - counts]*counts]] Out[]=(*这里的输出有多于36万个元素，不进行列举*) UnitStep在x＜0时取0，x≥0时取1。\n再画一下图：\n1 ArrayPlot[UnitStep[300 - counts]*counts] 改个颜色：\n1 ArrayPlot[UnitStep[300 - counts]*counts,ColorFunction-\u0026gt;\u0026#34;AvocadoColor\u0026#34;] 大功告成！\n更严重的问题 到现在为止，题干的问题就算解决了，我们得到了一个环，还是带刺的。\n那如果是24次方程呢？\n时间不是最大的问题，最大的问题在内存上，反正我是不敢在我的小家伙上跑这玩意儿了。问题在哪儿呢？肯定不在那2的24次方个±1上，那就只可能在遍历上了。Mathematica在遍历的时候是不对已遍历的数据进行处理的，也就是说，连带着已经遍历完的数据，原始数据，正在遍历的数据和还没遍历的数据一起堆在了内存里，这就很可怕了。\n想想办法，生成一个，计算一个，扔掉一个。\n无论怎么生成，我们最终要的是1和-1组成的序列，所以我们可以使用二进制生成。\n1 gene[num_,n_]:=(-1.)^IntegerDigits[num,2,n]; 这个函数生成-1与长为n的二进制序列的每一位的幂的List。\n但是如果用这个的话BinCounts又用不了了，因为它一次只产生一组方程的解。\n所以又要重写计数函数。\n至于这部分，还是参考原帖吧，放弃复原了……\n尾声 实在话，讲Mathematica是不那么简单的事儿，因为它的语法糖和函数嵌套实在是多得丧心病狂。自己用还行，一讲就寄了。最早准备讲讲Julia，结果我用了半天发现这玩意儿连包都不成气候那还用个锤子。我宁愿下次讲MATLAB，Python因为肚子里头没啥关于Python的油水一开始就没考虑。\n至于今天讲的内容，如果你看不懂编程语言也没关系，总之就是探索了如何高效地解大量的方程并将它们的解可视化。\n大概率如果下次讨论交流不会整这么大的花活儿了，毕竟肚子里头的油水也不是取之不尽用之不竭的，还得再添才是。\n参考链接：\nhttps://jump2.bdimg.com/p/3622255435?pn=1\n","date":"2024-12-18T21:38:49+08:00","permalink":"https://vzstless.moe/p/%E7%B3%BB%E6%95%B0%E4%B8%BA1%E7%9A%84n%E6%AC%A1%E6%96%B9%E7%A8%8B%E6%A0%B9%E5%9C%A8%E5%A4%8D%E5%B9%B3%E9%9D%A2%E7%9A%84%E5%88%86%E5%B8%83/","title":"系数为±1的n次方程根在复平面的分布"},{"content":"注：以下讨论不涉及C，Python和JavaScript，因为你不用也得用，迟早有一天你会被这仨语言中的一个找上茬儿\n马原课本告诉我们，生产力决定生产关系，生产关系反作用于生产力。我们可以使用这个理论来给计算机行业中的错误思想套公式。现在许多人中流传着Java焦虑，好像Java死了我的工作就彻底寄了，然后经典的中年危机就业焦虑。然而大概率事实是不是Java不行，而是你从始至终就没入行。换语言不会使你干好，反而你长期囿于原先的生产关系而没有意识到自己的生产力本身落后，换了语言，原形毕露，没有论坛可查，自己失去了debug和查找性能瓶颈的能力。类似的还有软件工程。首先，你大概率不是CEO之类的要职，而你的第一个demo做得并不好甚至没做出来，你就觉得现在的软件生产模型不行，想从瀑布模型转变成敏捷模型。然而你没注意到敏捷模型对生产力的要求是达到了一定境界的，你的生产力并不足以满足敏捷模型短期迭代的内在要求，大概率结局是项目流产。\n换一个视角，你应该在简历上写精通XXX语言吗？理论上不应该。这时候就有人问有人就看简历里头的这玩意儿你咋办嘛，我只能说这玩意儿只能反映你接触过这种生产关系，对于你的生产力没有任何反映。你用解释型编程语言大写特写for循环，最后的结果必定是慢的要死。当你想要入坑一个新的编程语言的时候，最好问问自己：\n它和我知道的编程语言有没有本质区别？\n学会C的人应该接触Python，因为Python是解释型，大量使用库函数的语言而C是编译型，造轮子的语言。Rust和C就没有本质区别，你最开始制作demo的时候对安全没有那样强烈的需求，甚至对cargo一类的项目管理器没什么需求，而你编程经验又不足，你就最好先别弄Rust，而是用C先做一个能跑的东西。\n最后，不妨思考一下这门语言为什么出现。C是UNIX的副产物，C++是为了改进C而产生的，Python脱胎于科学计算，Rust又被Mozilla用于浏览器内核的开发。从这个角度讲也许用Rust重构Chromium比用Rust重构Linux更现实？\n","date":"2024-12-16T21:51:39+08:00","permalink":"https://vzstless.moe/p/%E7%94%9F%E4%BA%A7%E5%8A%9B%E4%B8%8E%E7%94%9F%E4%BA%A7%E5%85%B3%E7%B3%BB/","title":"生产力与生产关系"},{"content":"事先声明，锐评不代表讨厌，相反，正是因为你有了足够的了解之后你才能知道为啥人家的课程好，我们的为什么烂。我感谢它们，在无数节水课中带我消磨时间，做有趣的事情。\nSICP SICP这个课可就有点儿历史了，上世纪80年代，Abelson和Sussman这俩人用他们编写的教科书改造了MIT的计算机入门课程。它主要使用Lisp的一门方言——MIT Scheme进行编程，讲解关于计算机思维与计算方法的基础知识。现在网上流传的始祖SICP实质上是两个教授去惠普公司进行的讲座，不过内容大同小异就是了。说是基础，但是这个课联同这本书都是极其折磨的。\n首先，Scheme，或者说Lisp系的语言只能写递归不能写迭代。这门课程的起初就在不断地教你如何递归展开。随后便是一些时至今日也在使用的编程语言设计理念的雏形——数据结构，面向对象，流，乃至并发。不要用你学某个现代化程度很高的编程语言的经验简单套用在这里，Lisp的bare metal程度某种意义上不亚于C，许多的现有的知识要先有一层抽象才能转化成Lisp的东西。以及这本书会大量地造轮子。造图片编程语言，造小型SQL，造基于Lisp-Like汇编语言的寄存器机器。对，某种意义上你现有的对于计算机的知识都被颠覆了，这本书告诉你只要有了Lisp你能造出来所有东西！\n当时学的时候我用了先看课再看书的策略，结果发现书上的题目和前头的知识完全就是雕花和切冻肉的关系（笑）。经常有第一题“来，仿照那个加法程序造一个乘法程序”，第二题“来，刚才用迭代写的同学转化成递归来写，刚才用递归的同学用迭代来写！”，第三题“你看，加法和乘法可以抽象成XXX，这个程序怎么写呢？”，第四题又是迭代换递归，递归换迭代，第五题又再抽象一层，抽象到最后还不忘问你一句“嘿，你觉得你的设计真的合理吗？”，绝大多数情况下我做到第三题就破大防去抄答案了。\n第四章和第五章虽说是讲evaluator，SQL和寄存器机器这种显而易见的东西，但是在书里头这玩意儿又被一层又一层抽象了。后来我转念一想“估计这点儿玩意儿我这辈子都用不上了”，就去做了一下“Build your own Lisp”，把第四章和第五章的课程录像看完了就跑了。\n现在想想UCB和MIT把这个课程改成Python，SQL和Lisp真是明智的选择。他们从函数入手而不是递归，大大降低了这门课程的门槛，第四章原来的造轮子变成了摆在眼前的SQL，之于更高层次的抽象则交给了Lisp。Sussman曾经暗讽过这个课程改变是让人做脱离系统的调包侠，但是调包不也是优化程序的一种有效手段吗？何况这个课程的教授方式也大变了，先让你熟悉终端，相关硬件的下载和从网站上获取压缩包。这个知识屏蔽已经到极致了。没有git，没有链接，没有过于繁杂的命令行，总之个人认为这个课程进步了很多。\n有人会问推不推荐学CS61A，我说你要是大佬休闲想学学无所谓。至于老版的SICP和配套的那本书，实在话，还是直接进入历史的故纸堆就好。我读过了，不建议你走同样的路。顺带一提，负责原始版本SICP翻译的HIT IBM俱乐部今日也某种意义上“半死不活”了。\nAlgorithms 最初接触这玩意儿的时候是我淘书的时候发现的人民邮电出版社的中译本，“与TAOCP相媲美的神作”，豁，那可得看看咯。结果第一章就看不懂了，作者居然自己搓了个Java标准库用，还得自己配，然后就是极其痛苦的配环境，最后环境没弄成，这本书就吃灰了。\n后来听人说Sedgewick的课比书好，我就去看课，看完就用C++尝试把示例代码重构了。但是有一整章的代码我都重构失败了，就是图算法。这本书绝大多数的代码都依赖于作者自己搓的标准库中的API，这就导致图算法重构的时候源代码毫无参考性，你就只能去诸如OI wiki的地方寻找。我严重怀疑这个所谓的“抽象数据结构”的思想给国内诸如严蔚敏《数据结构》一类的差评如潮的教材开了个坏头。如果我都无法将你的算法思维进行有效的迁移，那你这个课又有什么用呢？\n有！确切来讲是另一种意义上的。这门课会告诉你专业人士是怎么研究算法的。而且这个课很“新”。2007年Sedgewick将Red-Black BST进行了简化，变成了LLRB-BST，2012年，这个研究就被写入了教材。某种意义上这门课程给了你一种“这个算法牛逼吗？我发明的！”的一种震撼。\n于你而言这门课其实只需要看四个地方：开头的并查集优化，快速排序在大量重复关键字下的优化，左斜红黑树和3-Way Trie。这几个算法各有特色，而且有Sedgewick教授的原创成分。相信我，当你看见demo中的红黑树就像被赋予生命了一样自动平衡的时候你会发自内心大吼一句“卧槽”的。\n","date":"2024-12-15T13:38:47+08:00","permalink":"https://vzstless.moe/p/%E5%85%B3%E4%BA%8E%E4%B8%80%E4%BA%9B%E7%BD%91%E7%BB%9C%E7%83%AD%E9%97%A8%E8%AF%BE%E7%A8%8B/","title":"关于一些网络热门课程"},{"content":"单调栈 栈中元素从栈顶到栈底依次递增\n一个新数字进栈前要弹出所有比它小的数，所有数字都入栈\n例题：洛谷P2947\n哈夫曼编码 原理略\n例题：poj 1521\n优先队列与堆 使用priority_queue可以避免手动管理堆的实现代码\n例题：洛谷P3378\n重点是中间的priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; q;\n","date":"2024-12-11T10:17:29+08:00","permalink":"https://vzstless.moe/p/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/","title":"《算法竞赛》第一章笔记"},{"content":"单周期处理器（LA版本） 延迟槽：曾几何时它很好，然而它非但无法解决延迟造成的流水线阻塞问题，而且会使微结构的设计复杂化，而且编译器并不能总是提取出有效指令填入流水线导致流水线中出现过量空指令，影响流水线性能\n支持远距离跳转的指令集可以更好减少由于代码体积增大而产生的效率降低问题\n跳转后还要从寄存器中获得对应的地址，故称间接跳转，link用于返回地址的链接\n去掉unsigned的指令集依然是完整的\n至少需要一条syscall才能使用操作系统，否则指令集无法区分用户态和核心态\n务必注意当input的取值是最后一个值的时候的output\nCPU = 数据通路 + 控制逻辑\n指令在指令存储器中存储，地址为PC\n每执行完一条指令，PC = PC + 4\n指令存储器是一个静态存储器，所有写的端口恒为0\nadd.w: 从寄存器堆读取操作数，相加，写回寄存器堆\n寄存器堆的读端口必须有两个，否则执行add需要两个周期；而写端口要有enable（或者reset）\naddi.w: 与add.w唯一的区别就是第二个源操作数来自指令集中立即数符号扩展至32位\nld.w可以复用addi.w的数据通路，ld.w从从数据存储器中读取数据，取回的数据与加法器结果二选一放入寄存器堆\nst.w写数据存储器，不写寄存器堆\n务必注意：st.w的源操作数来自rd域，因为增加一个读端口会增加硬件开销\ndest bne = PC + offset\nbne根据判断的结果决定是否跳转\n每次加指令时进行的检查：本条指令是否正确运行，已有的指令功能是否正常\nzero寄存器的作用就是减少实现指令集子集时的xor\n编写控制信号的真值表\n存储器本质上属于核外单元，一些实际的案例中CPU的最顶层只有CLK和RESET\n现如今的EDA几乎可以把电路性能优化到极致，所以要以可读性与可维护性作为更高的目标\n不要写真值表，画卡诺图，直接对照指令的机器码格式和电路图敲Verilog\n多一条assign可以提高代码可读性\nb: 立即数增宽至26位\nbl:b之后将PC + 4写入r1（单周期甚至可以直接拉线到MUX写入）\n新增的控制信号依然要考虑所有的指令\n","date":"2024-12-10T16:55:17+08:00","permalink":"https://vzstless.moe/p/%E5%8D%95%E5%91%A8%E6%9C%9F%E5%A4%84%E7%90%86%E5%99%A8la%E8%AE%B2%E5%BA%A7%E7%AC%94%E8%AE%B0/","title":"单周期处理器（LA）讲座笔记"},{"content":"（注：这篇文章成文于一年前，放在博客上只是为了留档）\n最开始接触这玩意儿其实是因为前端（一朝做贼，再想做好人可不容易啊），菜鸟教程推荐的编辑器里头有VSCode，Sublime和WebStorm，这仨里头VSC配C的环境给我配出心理阴影了，而且这玩意儿甚至原生不支持ctrl+滚轮缩放字体。WS要钱，一年两千八，我说我别tm做个前端还得贴钱打工，于是选了Sublime，不得不承认这玩意儿确实好使得一批，现在除了C，Python和Mathematica直接Sublime+命令行，真正做到了有高亮有编译器就能写。\n这篇文章的内容全部为个人总结，毕竟网上能找到的Sublime教程都挺乐色的。\n基本使用方法 下载的话直接下就行，这玩意儿反正免费，不过保存文件的时候会时不时蹦个小窗口要你买License，有点烦人，不必管它。\n建议使用原生英文环境，毕竟那几个单词也不难，中文得装包，而且多语言包其实不好用，有一些词语原来是英文到头还是英文。\n双击快捷方式进入，View，SideBar，Show SideBar，调出来侧边栏，这样你就能看到你打开的文件。\nFile，New File可以新创建一个文件（注意这个文件是缺少后缀的），Open File可以打开一个文件并自动匹配高亮。\nNew File之后的第一件事务必先View，Syntax里头找这个语言的高亮，这不仅可以给你敲代码带来方便还能为你的代码文件添加对应的后缀（比如C的.c，Python的.py）\n一些关键字，头文件和函数会有对应的联想，如果想使用这些联想（或者叫补全）就即使按下Tab应用。\n敲完代码后ctrl+S保存\n高级技巧（也许？） ctrl+shift+P会打开一个搜索框，输入install，找到PackageInstaller就可以安装一些包让你的sublime变得花里胡哨。\n卸载Package输入remove即可\n比如你想要某个语言的高亮而Syntax找不见的时候就可以搜索这个语言的名称安装高亮和文件后缀支持。 搜索Chinese可以找到多语言支持不过不好使。 Emmet，直到我从前端滚蛋了四个月我才装这个包\nctrl+F在文件中进行搜索\n左手双指滑动右手按住鼠标就可以控制选中文本的速度，适用于没怎么学快捷键而单用鼠标控制不住文本选择的人\nctrl+P添加//注释\nctrl+shift+P添加/* 注释* /\nctrl+F 全局查找对应关键词\n至于其他的快捷键可以直接搜索对应关键词，不过我没咋用过别的快捷键就是了\nEdit里的Undo和Redo可以用来吃后悔药\n没保存也没关系，Sublime的逻辑是打开后自动开启上个工作文件的已有进程\n每行旁边如果有个倒三角可以进行代码缩略（常见于函数和CSS样式表）（这玩意儿在编CSS的时候救了我的老命要不然眼睛迟早得完蛋）\n右侧的代码预览可以快速转移至文件的某处代码\n环境变量中添加\u0026hellip;\u0026hellip;\\Sublime Text后可以使用Sublime的shell命令\nsubl 直接打开\nsubl 文件名 新建文件（Sublime直至你指定前不进行文件保存工作）\n","date":"2024-12-10T16:52:35+08:00","permalink":"https://vzstless.moe/p/%E4%B8%80%E5%88%86%E9%92%9F%E4%B8%8A%E6%89%8Bsublime/","title":"一分钟上手Sublime"},{"content":"4.1 prelude PC holds the address of the instruction that currently executed.\nregisters, base pointer, stack pointer\ncondition code: ZF, SF, OF\nmemory(monolithic byte array)\nTypes of encoding the Y-86 instructions:\nI-type, D-type and B-type\ninstructions movq is split: I, R, M -\u0026gt; R, M\nAL instructions: addq, subq, andq, xorq (as there is no zero register in Y-86 processor, you must add an xorq instruction)\njumps: jmp, \u0026lt;=, \u0026lt;, ==, !=, \u0026gt;=, \u0026gt;\ncond move: \u0026lt;=, \u0026lt;, ==, !=, \u0026gt;=, \u0026gt;\nhalt: stops the program\nencode code + function\nstore in a small RAM\nno ambiguity when encoding the instructions\nY86-64 is CISC-like for its various length of instructions and RISC-like for its single load/store encoding\nexceptions AOK, HLT, ADR, INS\nshut whenever not AOK\nrun a code addq needs another register but subq can also set the stat code\npushq and popq\u0026rsquo;s details may largely reduce the code portability, problem may occur when subq compares rsp and the pushed value, or pop the stack pointer, undefined behavior always annoy people anytime anywhere.\n4.2 components combinational logic, memory elements, clock signals(sequential logic is split into two parts)\nsimilarity: Verilog -\u0026gt; C, VHDL -\u0026gt; Ada\nHCL == block:\nbool eq = (a \u0026amp;\u0026amp; b) || (!a \u0026amp;\u0026amp; !b)\nHCL MUX block:\nbool out = (s \u0026amp;\u0026amp; a) || ()\nword level: using cases\n1 2 3 4 word Out = [ s: A; 1: B; ]; sequential logic reg \u0026amp; RAM\nstate changes only when clock rises\nsimple regfile:\nvalA, valB, srcA, srcB, dstW, valW\nin the Y86 processor: a memory with 2 ports, one for R inst, the other for R/W data\n4.3 stages of instructions Fetch PC = memaddr\nvalP = PC + len(inst)\nDecode read operands from reg file\nExecute ALU performs instruction or incr/decr the stack pointer, for other instruction, similar\nMemory W/R data in mem\nWrite back write back to register\nPC update PC stores addr of next instruction\ncost of adding hardware \u0026gt; cost of copying code in software\nprocess similar instructions in same manners\nHardware Fetch: PC computes valP, the incremented PC.\nDecode: read valA and valB\nExecute: ALU calculates integer or increments the stack pointer, decides whether jump or not.\nMemory: read or write a word of mem\nWrite Back: write back from ALU or mem\nPC update\nonly start next cycle when clock rises\nprocessor never read back\neg: no instruction will both set and read the cond code\neg: stack pointer\nfetch: fetching 6 bytes and generate instruction fields.\ndecode \u0026amp; write back: generate register identifiers, serve necessary data.\nexecute: ALU performs as the calculator or just the adder.\nmemory: write or read memory values.\nPC increment: depend on instruction code or branch or not.\nSurvey the clock must run slow enough to suit the single-cycle.\nthe parts of the processor only active for a single part of time in the clock cycle\n4.4 pipelining divide into a series of discrete stages\nincrease the throughput of a system, but slightly increase the latency\nnonpipelined: a logic performs the computation with a register hold the result of the computation\nlatency: the total time to perform a single instruction\nslowing the clock won\u0026rsquo;t change the behavior of a pipeline.\ndifferent clock delays of different instructions influences the pipeline,\ndue to the delay, pipeline doesn\u0026rsquo;t always have larger throughput with more stages on each instruction\nlogical dependencies limits the performance of pipeline\n","date":"2024-12-10T16:44:47+08:00","permalink":"https://vzstless.moe/p/csapp-chapter4/","title":"Csapp Chapter4"},{"content":"(This is the first version of my README)\nVZstless as your friend or thinker 🍥 Call this name as VictorZhang was signed up by somebody else\u0026hellip; 👻 Love frontend in any perspective, digital, or web. 🐣 Libre \u0026amp; OpenSource aholic. ⭐ Still an undergraduate and a crazyone. 🐧 A human-like history book or cheatsheet. ✉️ 2319725508@qq.com 🍀I work so I live. ","date":"2024-12-09T20:45:32+08:00","permalink":"https://vzstless.moe/p/whoami/","title":"Whoami"}]