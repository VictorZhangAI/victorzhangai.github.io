[{"content":"Handout 1 Purpose of an OS:\nIsolate hard/software, virtualize hardware\nInteract with OS via syscalls\nFirst arg in syscall is FD\nUNIX I/O is 8-bit bytes\nWhen CPU receives a syscall:\nsave, jump, execute, call, restore, reduce, jump back\nShell is a user program instead of shell\nfork() lets us create a new process\nexec() replaces current process with an executable file\nBook Chapter 1 Operating system let different softwares use hardware together\nProcess: instructions, data, stack\nfork() returns 0 in the child process while pid in the parent process\nwait() returns the pid and copies the exit status\nexec() loads a file and executes it\nfile descripter refers to a file.\nfork() and exec()let the shell has the chance to redirect child\u0026rsquo;s I/O\nFile descripter is a good abstraction\nPipe is a small kernel buffer conncting files.\nPipe: auto-clean, pass long data, allow parallel execution\nUnderlying file is called inode\ncd is built-in, if not, the shell will form a infinity process tree of dir-changing\nALL XV6 PROGRAMS RUN AS ROOT!!!!!\nAmusement: UNIX In order to avoid large amount of team population and project cost, we need to build a good programming environment. UNIX is for building such an environment.\nPROBLEM: Large number of softwares, large scale of jobs\nSoftware is always demanded for different operations, to avoid rewrite code per annum, the code should be divided into modules. Layers: kernel, shell, util\nA show of pipes\nEasy and packed pattern-matching algorithms\nRefer file as a simple sequence of bytes, file is contained in directories\nConcept of I/O redirection\nC: If you need to avoid hardware, simply use it; but also ways to interact with hardware directly\nAn example of a software, inputting boolean equation and outputting circuit traces\nComputer is built for easy to use\nLecture 1 What would a kernel do?\nEveryone thought OS provides what they already know\nMany tensions occurred in OS design\nFunc call vs Syscall? func hasn\u0026rsquo;t previlege to access real CPU and mem but syscalls have\nHigh-level language is designed to be portable\nThere is a rule that we read from fd 0 and write to fd 1\nKernel holds a process table and guided by fd\nInstruction ecall passes the system from user space to the kernel space\nParent and child process shares the same fd\nexec() loads the program in the file and throw away current process\nexec() remains the fd that already exists\nwait() waits the child process to return, if the process hasn\u0026rsquo;t child process, it\u0026rsquo;ll return -1\n","date":"2025-01-01T08:28:39+08:00","permalink":"https://victorzhangai.github.io/p/xv6-lecture1/","title":"xv6 LECTURE1"},{"content":"理论上一个计算机都快学不明白的人不应该对外行的见识发表暴论，但既然学校选择了力推外专业“选修”，不修毕不了业，那我就不先礼后兵了\n许多人现如今已经不太看重所谓的MBA或者别的类似的商学学位，认为它们纯纯是二水货，事实证明他们没错。商学的死不是因为商学被什么别的哲学取代了，而是商学被计算机从思维意义上被取代了。这时候你大概率要问：是计算机代替了人力参与了商学相关的事务了吗？是也不是，因为不只是人类意义上的代替，还有思想层面的代替。\n几乎所有的管理学相关的思想在计算机哲学中都能找到代替品，而且研究层面上更加极端。流水线优化与对节拍异化为了CPU流水线性能优化，工作中心分配异化为了操作系统中的线程调度优化，公交线路布局异化为了找最长路径，观察次数异化为了单纯的统计题，工序优化异化为了对一个有向图进行拓扑排序，至于剩下的，大概率交给Excel或者大模型都可以完成。从思想和实践层面，计算机科学都直接毙掉了商学。\n也许商学的下一步应该把UNIX编程艺术列为必读书目？但总之不应该是罗宾斯管理学这种老东西了。\n","date":"2024-12-30T08:08:50+08:00","permalink":"https://victorzhangai.github.io/p/%E5%95%86%E5%AD%A6%E7%9A%84%E6%AD%BB%E4%BA%A1/","title":"商学的死亡"},{"content":"（一篇在分享会上的稿件的留档）\n引子 Mathematica的基础语法三句话就能解决：\n1.内置函数的每个单词以大写字母开头。\n2.函数用[]传参。\n3.List用{}包围。\n1 2 {1，2，3} {{1，2}，{3，4}} 由于Mathematica的语法糖实在是太多太多太多了，所以这里我尽量使用最基础的语法。可能看着不好看，但是保看懂。（Mathematica不带转义md的功能，所以这个文档的代码显示并不好）\n这个问题来自于10年前百度贴吧Mathematica吧的一个帖子，我们尝试复现一下这个问题。\n生成方程并提取方程的解 系数为±1的二次方程长这样：\n1 2 3 4 In[]:=x^Range[0, 2] . # == 0 \u0026amp; /@ Tuples[{-1, 1}, 3] Out[]={-1 - x - x^2 == 0, -1 - x + x^2 == 0, -1 + x - x^2 == 0, -1 + x + x^2 == 0, 1 - x - x^2 == 0, 1 - x + x^2 == 0, 1 + x - x^2 == 0, 1 + x + x^2 == 0} In和Out代表运行语句和运行结果，不用管它们。你只需要看Out后头生成的东西。这里使用的生成方法是穷举-1和1的n+1元组合与x的从0到n次幂点乘等于0。但是这个方法有点儿慢，用代数数可以快点儿。\n1 2 In[]:=AlgebraicNumber[x, {1, -1, 1, 1, -1}] == 0 Out[]=1 - x + x^2 + x^3 - x^4 == 0 严格来说，Mathematica内部的代数数函数是有点儿问题的，因为它允许系数取实数范围，不过这不重要，重点是我们生成了一个符合题干要求的方程，而且这个语法比上头那个好使一万倍。\n接下来，解方程。先想到的肯定是NSolve，Solve用于求某个方程的解析解，NSolve用于求某个方程的数值解。\n1 2 In[]:=NSolve[AlgebraicNumber[x, {1, -1, 1}] == 0, x] Out[]={{x -\u0026gt; 0.5 - 0.866025 I}, {x -\u0026gt; 0.5 + 0.866025 I}} 画图肯定不能指望这玩意儿画，所以要想办法提取出来解。用TreeForm分析层次（或者瞪眼法也行）可知，第一层是包含两个List的List，第二层是包含每个解的List，第三层是-\u0026gt;（Mathematica中称为Rule）。[[]]可以用来提取解，而ReIm函数可以将解的实部和虚部生成一个List返回。\n1 2 In[]:=ReIm[NSolve[AlgebraicNumber[x, {1, -1, 1}] == 0, x][[All, 1, 2]]] Out[]={{0.5, -0.866025}, {0.5, 0.866025}} 尝试画个图先\n1 In[]:=ListPlot[ReIm[NSolve[AlgebraicNumber[x, {#1, #2, #3, #4, #5, #6, #7, #8, #9, #10}] ==0, x][[All, 1, 2]]] \u0026amp; @@@ Tuples[{-1, 1}, 10]] 其中ListPlot为绘制散点图，@@@用于替换表达式的一级标头（TreeForm的第一层），#和\u0026amp;为纯函数的自变量和结尾标识，这个图长这样：\n然后你发现你的电脑有点儿卡了。\n效率问题 我们循规蹈矩一点儿，至少还有两招能用。\n1.小数比整数快。\n如果你在Mathematica计算1/2，结果会返回二分之一。同理的，解方程也会如此。\n1 2 3 4 In[]:=Solve[2 x^2 + 3 x + 4 == 0, x] Out[]={{x -\u0026gt; 1/4 (-3 - I Sqrt[23])}, {x -\u0026gt; 1/4 (-3 + I Sqrt[23])}} In[]:=Solve[2.0 x^2 + 3.0 x + 4.0 == 0.0, x] Out[]={{x -\u0026gt; -0.75 - 1.19896 I}, {x -\u0026gt; -0.75 + 1.19896 I}} Mathematica中整数的精度不是1，而是无穷。我们显然不需要那么高的精度，用机器精度足以完成任务了。\n2.专用函数比通用函数快。\nSolve和NSolve的求解原理是求f(x)=0的反函数，对于超越方程来说，没办法，只能是它。但是我们今天的主角是多项式，可以有更快的方法。\n1 2 In[]:= NRoots[AlgebraicNumber[x, {1, -1, 1}] == 0, x] Out[]=x == 0.5 - 0.866025 I || x == 0.5 + 0.866025 I NRoots给出一个多项式方程的数值近似解。\n验证一下NRoots和NSolve哪个更快,求解1000个方程比较一下。\n1 2 3 4 In[]:=AbsoluteTiming[Do[List@@NRoots[AlgebraicNumber[x, {4., 3., 2., 1.}] == 0, x][[All, 2]], {1000}]] Out[]={0.0411889, Null} In[]:=AbsoluteTiming[Do[List@@NRoots[AlgebraicNumber[x, {4., 3., 2., 1.}] == 0, x][[All, 1, 2]], {1000}]] Out[]={1.1734, Null} 一个0.04秒，一个1.17秒，差距相当明显。\n如法炮制，我们观察一下结构（或者使用TreeForm），第一层是Or，也就是||，第二层是用Equal（==）连接的x与对应解。开始替换。\n1 2 In[]:=ReIm[List @@ NRoots[AlgebraicNumber[x, {1, -1, 1}] == 0, x][[All, 2]]] Out[]={{0.5, -0.866025}, {0.5, 0.866025}} 理论上，只要把这玩意儿封装成函数，画个散点图这事儿就结束了。但是还是别这样了，我试过了，13次方程，用了65秒，全程内存占用没下700M。\n师夷长技以制夷 思考一个问题：我真的需要求出所有的方程的解吗？\nx^2+x+1==0和-x^2-x-1==0的解是一模一样的，之前生成的这些方程中有一半是求解了也没用的。所以我们只需要考虑最高次系数为正1的情形。\n1 f[list_]:=List@@NRoots[AlgebraicNumber[x,Append[list,1]]==0,x][[All,2]] Append用于在列表末尾插入值。\n再试试？\n1 2 In[]:=AbsoluteTiming[f /@ Tuples[{-1, 1}, 13]] Out[]={6.16429,{...}} 现在我们倒是求出来了13次方程的所有解，然而吧主的最终图像中求解了19次方程，这个时间是6.16秒的5个数量级，而且这还没计算画图时间。显然，这是我们承受不起的。\n然后，我们发现了一个悲哀的事实：\nMathematica中NRoots的求解效率比MATLAB中的roots低了一个数量级！\n幸运的是，MATLAB可以随意篡改函数的源代码，一句话就可以一睹这个函数的芳容：\n1 edit(which(\u0026#34;roots.m\u0026#34;)) 举例说明一下原理：\n$$ a_3x^3+a_2x^2+a_1x+a_0=0 $$$$ A=\\begin{bmatrix} -\\frac{a_2}{a_3} \u0026 -\\frac{a_1}{a_3} \u0026-\\frac{a_0}{a_3} \\\\ 1 \u0026 0 \u0026 0\\\\ 0 \u0026 1 \u0026 0 \\end{bmatrix} $$$$ x=\\begin{bmatrix} x_1\\\\x_2\\\\x_3 \\end{bmatrix} $$$$ \\begin{matrix} -\\frac{a_2}{a_3}x_1-\\frac{a_1}{a_3}x_2-\\frac{a_0}{a_3}x_3=\\lambda x_1\\\\ x_1=\\lambda x_2\\\\ x_2=\\lambda x_3 \\end{matrix} $$ 代入原方程就可以把求解方程的解转化为求解矩阵的特征值，以上原理对n次方程依然成立。\n明白了原理就可以自己写一个类似的，不过我们只要系数±1的情况所以不必完全照抄。\n1 2 3 4 modifiedroots[c_List]:=Module[{a},a=DiagonalMatrix[ConstantArray[1.,Length[c]-1],-1]; a[[1]]=-c; Eigenvalues[a] ]; （顺带一提Mathematica里头用个局部变量麻烦得可怕，同样可怕的是字符串拼接，不过今天的内容不涉及）\n算14次方程的时候这个函数竟然只用了1.23秒！（我们一共计算了2^14个方程）\n准备绘图。不过我们换个方式。前头的两个散点图太难看了，我们改成密度图。\n首先对点的分布进行统计。既然效率提高了就直接上18次方程。\n1 2 3 4 5 In[]:=n = 18; data = ReIm[Flatten[modifiedroots /@ Tuples[{-1, 1}, n]]]; counts = BinCounts[data, {-2, 2, 4./601}, {-2., 2., 4./601}]; Sort[Flatten[counts]] Out[]=(*这里的输出有多于36万个元素，不进行列举*) 将统计结果转化为平面直角坐标系中的对应点的灰度：\n1 ArrayPlot[counts] 大概长这样：\n合理的篡改 这个图并不好看，甚至于说没有观察价值。\n回到数据观察，我们发现这个数据集中有一大半的0和一大半1000以上的数据。光学的衍射实验中也有类似的情况，称为衍射主极大。我们平常在书上看到的衍射图样都是被处理过的，实际上，真正的衍射实验中中间的条纹光强是远高于边缘的小条纹的。\n1 2 In[]:=Sort[Flatten[UnitStep[300 - counts]*counts]] Out[]=(*这里的输出有多于36万个元素，不进行列举*) UnitStep在x＜0时取0，x≥0时取1。\n再画一下图：\n1 ArrayPlot[UnitStep[300 - counts]*counts] 改个颜色：\n1 ArrayPlot[UnitStep[300 - counts]*counts,ColorFunction-\u0026gt;\u0026#34;AvocadoColor\u0026#34;] 大功告成！\n更严重的问题 到现在为止，题干的问题就算解决了，我们得到了一个环，还是带刺的。\n那如果是24次方程呢？\n时间不是最大的问题，最大的问题在内存上，反正我是不敢在我的小家伙上跑这玩意儿了。问题在哪儿呢？肯定不在那2的24次方个±1上，那就只可能在遍历上了。Mathematica在遍历的时候是不对已遍历的数据进行处理的，也就是说，连带着已经遍历完的数据，原始数据，正在遍历的数据和还没遍历的数据一起堆在了内存里，这就很可怕了。\n想想办法，生成一个，计算一个，扔掉一个。\n无论怎么生成，我们最终要的是1和-1组成的序列，所以我们可以使用二进制生成。\n1 gene[num_,n_]:=(-1.)^IntegerDigits[num,2,n]; 这个函数生成-1与长为n的二进制序列的每一位的幂的List。\n但是如果用这个的话BinCounts又用不了了，因为它一次只产生一组方程的解。\n所以又要重写计数函数。\n至于这部分，还是参考原帖吧，放弃复原了……\n尾声 实在话，讲Mathematica是不那么简单的事儿，因为它的语法糖和函数嵌套实在是多得丧心病狂。自己用还行，一讲就寄了。最早准备讲讲Julia，结果我用了半天发现这玩意儿连包都不成气候那还用个锤子。我宁愿下次讲MATLAB，Python因为肚子里头没啥关于Python的油水一开始就没考虑。\n至于今天讲的内容，如果你看不懂编程语言也没关系，总之就是探索了如何高效地解大量的方程并将它们的解可视化。\n大概率如果下次讨论交流不会整这么大的花活儿了，毕竟肚子里头的油水也不是取之不尽用之不竭的，还得再添才是。\n参考链接：\nhttps://jump2.bdimg.com/p/3622255435?pn=1\n","date":"2024-12-18T21:38:49+08:00","permalink":"https://victorzhangai.github.io/p/%E7%B3%BB%E6%95%B0%E4%B8%BA1%E7%9A%84n%E6%AC%A1%E6%96%B9%E7%A8%8B%E6%A0%B9%E5%9C%A8%E5%A4%8D%E5%B9%B3%E9%9D%A2%E7%9A%84%E5%88%86%E5%B8%83/","title":"系数为±1的n次方程根在复平面的分布"},{"content":"注：以下讨论不涉及C，Python和JavaScript，因为你不用也得用，迟早有一天你会被这仨语言中的一个找上茬儿\n马原课本告诉我们，生产力决定生产关系，生产关系反作用于生产力。我们可以使用这个理论来给计算机行业中的错误思想套公式。现在许多人中流传着Java焦虑，好像Java死了我的工作就彻底寄了，然后经典的中年危机就业焦虑。然而大概率事实是不是Java不行，而是你从始至终就没入行。换语言不会使你干好，反而你长期囿于原先的生产关系而没有意识到自己的生产力本身落后，换了语言，原形毕露，没有论坛可查，自己失去了debug和查找性能瓶颈的能力。类似的还有软件工程。首先，你大概率不是CEO之类的要职，而你的第一个demo做得并不好甚至没做出来，你就觉得现在的软件生产模型不行，想从瀑布模型转变成敏捷模型。然而你没注意到敏捷模型对生产力的要求是达到了一定境界的，你的生产力并不足以满足敏捷模型短期迭代的内在要求，大概率结局是项目流产。\n换一个视角，你应该在简历上写精通XXX语言吗？理论上不应该。这时候就有人问有人就看简历里头的这玩意儿你咋办嘛，我只能说这玩意儿只能反映你接触过这种生产关系，对于你的生产力没有任何反映。你用解释型编程语言大写特写for循环，最后的结果必定是慢的要死。当你想要入坑一个新的编程语言的时候，最好问问自己：\n它和我知道的编程语言有没有本质区别？\n学会C的人应该接触Python，因为Python是解释型，大量使用库函数的语言而C是编译型，造轮子的语言。Rust和C就没有本质区别，你最开始制作demo的时候对安全没有那样强烈的需求，甚至对cargo一类的项目管理器没什么需求，而你编程经验又不足，你就最好先别弄Rust，而是用C先做一个能跑的东西。\n最后，不妨思考一下这门语言为什么出现。C是UNIX的副产物，C++是为了改进C而产生的，Python脱胎于科学计算，Rust又被Mozilla用于浏览器内核的开发。从这个角度讲也许用Rust重构Chromium比用Rust重构Linux更现实？\n","date":"2024-12-16T21:51:39+08:00","permalink":"https://victorzhangai.github.io/p/%E7%94%9F%E4%BA%A7%E5%8A%9B%E4%B8%8E%E7%94%9F%E4%BA%A7%E5%85%B3%E7%B3%BB/","title":"生产力与生产关系"},{"content":"事先声明，锐评不代表讨厌，相反，正是因为你有了足够的了解之后你才能知道为啥人家的课程好，我们的为什么烂。我感谢它们，在无数节水课中带我消磨时间，做有趣的事情。\nSICP SICP这个课可就有点儿历史了，上世纪80年代，Abelson和Sussman这俩人用他们编写的教科书改造了MIT的计算机入门课程。它主要使用Lisp的一门方言——MIT Scheme进行编程，讲解关于计算机思维与计算方法的基础知识。现在网上流传的始祖SICP实质上是两个教授去惠普公司进行的讲座，不过内容大同小异就是了。说是基础，但是这个课联同这本书都是极其折磨的。\n首先，Scheme，或者说Lisp系的语言只能写递归不能写迭代。这门课程的起初就在不断地教你如何递归展开。随后便是一些时至今日也在使用的编程语言设计理念的雏形——数据结构，面向对象，流，乃至并发。不要用你学某个现代化程度很高的编程语言的经验简单套用在这里，Lisp的bare metal程度某种意义上不亚于C，许多的现有的知识要先有一层抽象才能转化成Lisp的东西。以及这本书会大量地造轮子。造图片编程语言，造小型SQL，造基于Lisp-Like汇编语言的寄存器机器。对，某种意义上你现有的对于计算机的知识都被颠覆了，这本书告诉你只要有了Lisp你能造出来所有东西！\n当时学的时候我用了先看课再看书的策略，结果发现书上的题目和前头的知识完全就是雕花和切冻肉的关系（笑）。经常有第一题“来，仿照那个加法程序造一个乘法程序”，第二题“来，刚才用迭代写的同学转化成递归来写，刚才用递归的同学用迭代来写！”，第三题“你看，加法和乘法可以抽象成XXX，这个程序怎么写呢？”，第四题又是迭代换递归，递归换迭代，第五题又再抽象一层，抽象到最后还不忘问你一句“嘿，你觉得你的设计真的合理吗？”，绝大多数情况下我做到第三题就破大防去抄答案了。\n第四章和第五章虽说是讲evaluator，SQL和寄存器机器这种显而易见的东西，但是在书里头这玩意儿又被一层又一层抽象了。后来我转念一想“估计这点儿玩意儿我这辈子都用不上了”，就去做了一下“Build your own Lisp”，把第四章和第五章的课程录像看完了就跑了。\n现在想想UCB和MIT把这个课程改成Python，SQL和Lisp真是明智的选择。他们从函数入手而不是递归，大大降低了这门课程的门槛，第四章原来的造轮子变成了摆在眼前的SQL，之于更高层次的抽象则交给了Lisp。Sussman曾经暗讽过这个课程改变是让人做脱离系统的调包侠，但是调包不也是优化程序的一种有效手段吗？何况这个课程的教授方式也大变了，先让你熟悉终端，相关硬件的下载和从网站上获取压缩包。这个知识屏蔽已经到极致了。没有git，没有链接，没有过于繁杂的命令行，总之个人认为这个课程进步了很多。\n有人会问推不推荐学CS61A，我说你要是大佬休闲想学学无所谓。至于老版的SICP和配套的那本书，实在话，还是直接进入历史的故纸堆就好。我读过了，不建议你走同样的路。顺带一提，负责原始版本SICP翻译的HIT IBM俱乐部今日也某种意义上“半死不活”了。\nAlgorithms 最初接触这玩意儿的时候是我淘书的时候发现的人民邮电出版社的中译本，“与TAOCP相媲美的神作”，豁，那可得看看咯。结果第一章就看不懂了，作者居然自己搓了个Java标准库用，还得自己配，然后就是极其痛苦的配环境，最后环境没弄成，这本书就吃灰了。\n后来听人说Sedgewick的课比书好，我就去看课，看完就用C++尝试把示例代码重构了。但是有一整章的代码我都重构失败了，就是图算法。这本书绝大多数的代码都依赖于作者自己搓的标准库中的API，这就导致图算法重构的时候源代码毫无参考性，你就只能去诸如OI wiki的地方寻找。我严重怀疑这个所谓的“抽象数据结构”的思想给国内诸如严蔚敏《数据结构》一类的差评如潮的教材开了个坏头。如果我都无法将你的算法思维进行有效的迁移，那你这个课又有什么用呢？\n有！确切来讲是另一种意义上的。这门课会告诉你专业人士是怎么研究算法的。而且这个课很“新”。2007年Sedgewick将Red-Black BST进行了简化，变成了LLRB-BST，2012年，这个研究就被写入了教材。某种意义上这门课程给了你一种“这个算法牛逼吗？我发明的！”的一种震撼。\n于你而言这门课其实只需要看四个地方：开头的并查集优化，快速排序在大量重复关键字下的优化，左斜红黑树和3-Way Trie。这几个算法各有特色，而且有Sedgewick教授的原创成分。相信我，当你看见demo中的红黑树就像被赋予生命了一样自动平衡的时候你会发自内心大吼一句“卧槽”的。\n","date":"2024-12-15T13:38:47+08:00","permalink":"https://victorzhangai.github.io/p/%E5%85%B3%E4%BA%8E%E4%B8%80%E4%BA%9B%E7%BD%91%E7%BB%9C%E7%83%AD%E9%97%A8%E8%AF%BE%E7%A8%8B/","title":"关于一些网络热门课程"},{"content":"单调栈 栈中元素从栈顶到栈底依次递增\n一个新数字进栈前要弹出所有比它小的数，所有数字都入栈\n例题：洛谷P2947\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; int h[100000], ans[100000]; int main() { stack\u0026lt;int\u0026gt; s; int n; scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); for(int i = 1; i \u0026lt;= n; i++) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;h[i]); } for(int i = n; i \u0026gt;= 1; i--) { while(!s.empty() \u0026amp;\u0026amp; h[s.top()] \u0026lt;= h[i]) s.pop(); if(s.empty()) ans[i] = 0; else ans[i] = s.top(); s.push(i); } for(int i = 1; i \u0026lt;= n; i++) printf(\u0026#34;%d\\n\u0026#34;, ans[i]); return 0; } 哈夫曼编码 例题：poj 1521\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; int main() { priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; q; string s; while(getline(cin, s) \u0026amp;\u0026amp; s != \u0026#34;END\u0026#34;) { sort(s.begin(), s.end()); int num = 1; for(int i = 1; i \u0026lt;= s.length(); i++) { if(s[i] != s[i - 1]) { q.push(num); num = 1; } else num++; } int ans = 0; if(q.size() == 1) ans = s.length(); while(q.size() \u0026gt; 1) { int a = q.top(); q.pop(); int b = q.top(); q.pop(); q.push(a + b); ans += a + b; } q.pop(); printf(\u0026#34;%d %d %.1f\\n\u0026#34;, s.length() * 8, ans, (double)s.length() * 8 / (double)ans); } return 0; } 优先队列与堆 使用priority_queue可以避免手动管理堆的实现代码\n例题：洛谷P3378\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; int main() { priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; q; int n; scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); while(n--) { int op; scanf(\u0026#34;%d\u0026#34;, \u0026amp;op); if(op == 1) { int x; scanf(\u0026#34;%d\u0026#34;, \u0026amp;x); q.push(x); } else if(op == 2) { printf(\u0026#34;%d\\n\u0026#34;, q.top()); } else q.pop(); } return 0; } 重点是中间的priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; q;\n","date":"2024-12-11T10:17:29+08:00","permalink":"https://victorzhangai.github.io/p/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/","title":"《算法竞赛》第一章笔记"},{"content":"单周期处理器（LA版本） 延迟槽：曾几何时它很好，然而它非但无法解决延迟造成的流水线阻塞问题，而且会使微结构的设计复杂化，而且编译器并不能总是提取出有效指令填入流水线导致流水线中出现过量空指令，影响流水线性能\n支持远距离跳转的指令集可以更好减少由于代码体积增大而产生的效率降低问题\n跳转后还要从寄存器中获得对应的地址，故称间接跳转，link用于返回地址的链接\n去掉unsigned的指令集依然是完整的\n至少需要一条syscall才能使用操作系统，否则指令集无法区分用户态和核心态\n务必注意当input的取值是最后一个值的时候的output\nCPU = 数据通路 + 控制逻辑\n指令在指令存储器中存储，地址为PC\n每执行完一条指令，PC = PC + 4\n指令存储器是一个静态存储器，所有写的端口恒为0\nadd.w: 从寄存器堆读取操作数，相加，写回寄存器堆\n寄存器堆的读端口必须有两个，否则执行add需要两个周期；而写端口要有enable（或者reset）\naddi.w: 与add.w唯一的区别就是第二个源操作数来自指令集中立即数符号扩展至32位\nld.w可以复用addi.w的数据通路，ld.w从从数据存储器中读取数据，取回的数据与加法器结果二选一放入寄存器堆\nst.w写数据存储器，不写寄存器堆\n务必注意：st.w的源操作数来自rd域，因为增加一个读端口会增加硬件开销\ndest bne = PC + offset\nbne根据判断的结果决定是否跳转\n每次加指令时进行的检查：本条指令是否正确运行，已有的指令功能是否正常\nzero寄存器的作用就是减少实现指令集子集时的xor\n编写控制信号的真值表\n存储器本质上属于核外单元，一些实际的案例中CPU的最顶层只有CLK和RESET\n现如今的EDA几乎可以把电路性能优化到极致，所以要以可读性与可维护性作为更高的目标\n不要写真值表，画卡诺图，直接对照指令的机器码格式和电路图敲Verilog\n多一条assign可以提高代码可读性\nb: 立即数增宽至26位\nbl:b之后将PC + 4写入r1（单周期甚至可以直接拉线到MUX写入）\n新增的控制信号依然要考虑所有的指令\n","date":"2024-12-10T16:55:17+08:00","permalink":"https://victorzhangai.github.io/p/%E5%8D%95%E5%91%A8%E6%9C%9F%E5%A4%84%E7%90%86%E5%99%A8la%E8%AE%B2%E5%BA%A7%E7%AC%94%E8%AE%B0/","title":"单周期处理器（LA）讲座笔记"},{"content":"（注：这篇文章成文于一年前，放在博客上只是为了留档）\n最开始接触这玩意儿其实是因为前端（一朝做贼，再想做好人可不容易啊），菜鸟教程推荐的编辑器里头有VSCode，Sublime和WebStorm，这仨里头VSC配C的环境给我配出心理阴影了，而且这玩意儿甚至原生不支持ctrl+滚轮缩放字体。WS要钱，一年两千八，我说我别tm做个前端还得贴钱打工，于是选了Sublime，不得不承认这玩意儿确实好使得一批，现在除了C，Python和Mathematica直接Sublime+命令行，真正做到了有高亮有编译器就能写。\n这篇文章的内容全部为个人总结，毕竟网上能找到的Sublime教程都挺乐色的。\n基本使用方法 下载的话直接下就行，这玩意儿反正免费，不过保存文件的时候会时不时蹦个小窗口要你买License，有点烦人，不必管它。\n建议使用原生英文环境，毕竟那几个单词也不难，中文得装包，而且多语言包其实不好用，有一些词语原来是英文到头还是英文。\n双击快捷方式进入，View，SideBar，Show SideBar，调出来侧边栏，这样你就能看到你打开的文件。\nFile，New File可以新创建一个文件（注意这个文件是缺少后缀的），Open File可以打开一个文件并自动匹配高亮。\nNew File之后的第一件事务必先View，Syntax里头找这个语言的高亮，这不仅可以给你敲代码带来方便还能为你的代码文件添加对应的后缀（比如C的.c，Python的.py）\n一些关键字，头文件和函数会有对应的联想，如果想使用这些联想（或者叫补全）就即使按下Tab应用。\n敲完代码后ctrl+S保存\n高级技巧（也许？） ctrl+shift+P会打开一个搜索框，输入install，找到PackageInstaller就可以安装一些包让你的sublime变得花里胡哨。\n卸载Package输入remove即可\n比如你想要某个语言的高亮而Syntax找不见的时候就可以搜索这个语言的名称安装高亮和文件后缀支持。 搜索Chinese可以找到多语言支持不过不好使。 Emmet，直到我从前端滚蛋了四个月我才装这个包\nctrl+F在文件中进行搜索\n左手双指滑动右手按住鼠标就可以控制选中文本的速度，适用于没怎么学快捷键而单用鼠标控制不住文本选择的人\nctrl+P添加//注释\nctrl+shift+P添加/* 注释* /\nctrl+F 全局查找对应关键词\n至于其他的快捷键可以直接搜索对应关键词，不过我没咋用过别的快捷键就是了\nEdit里的Undo和Redo可以用来吃后悔药\n没保存也没关系，Sublime的逻辑是打开后自动开启上个工作文件的已有进程\n每行旁边如果有个倒三角可以进行代码缩略（常见于函数和CSS样式表）（这玩意儿在编CSS的时候救了我的老命要不然眼睛迟早得完蛋）\n右侧的代码预览可以快速转移至文件的某处代码\n环境变量中添加\u0026hellip;\u0026hellip;\\Sublime Text后可以使用Sublime的shell命令\nsubl 直接打开\nsubl 文件名 新建文件（Sublime直至你指定前不进行文件保存工作）\n","date":"2024-12-10T16:52:35+08:00","permalink":"https://victorzhangai.github.io/p/%E4%B8%80%E5%88%86%E9%92%9F%E4%B8%8A%E6%89%8Bsublime/","title":"一分钟上手Sublime"},{"content":"4.1 prelude PC holds the address of the instruction that currently executed.\nregisters, base pointer, stack pointer\ncondition code: ZF, SF, OF\nmemory(monolithic byte array)\nTypes of encoding the Y-86 instructions:\nI-type, D-type and B-type\ninstructions movq is split: I, R, M -\u0026gt; R, M\nAL instructions: addq, subq, andq, xorq (as there is no zero register in Y-86 processor, you must add an xorq instruction)\njumps: jmp, \u0026lt;=, \u0026lt;, ==, !=, \u0026gt;=, \u0026gt;\ncond move: \u0026lt;=, \u0026lt;, ==, !=, \u0026gt;=, \u0026gt;\nhalt: stops the program\nencode code + function\nstore in a small RAM\nno ambiguity when encoding the instructions\nY86-64 is CISC-like for its various length of instructions and RISC-like for its single load/store encoding\nexceptions AOK, HLT, ADR, INS\nshut whenever not AOK\nrun a code addq needs another register but subq can also set the stat code\npushq and popq\u0026rsquo;s details may largely reduce the code portability, problem may occur when subq compares rsp and the pushed value, or pop the stack pointer, undefined behavior always annoy people anytime anywhere.\n4.2 components combinational logic, memory elements, clock signals(sequential logic is split into two parts)\nsimilarity: Verilog -\u0026gt; C, VHDL -\u0026gt; Ada\nHCL == block:\nbool eq = (a \u0026amp;\u0026amp; b) || (!a \u0026amp;\u0026amp; !b)\nHCL MUX block:\nbool out = (s \u0026amp;\u0026amp; a) || ()\nword level: using cases\n1 2 3 4 word Out = [ s: A; 1: B; ]; sequential logic reg \u0026amp; RAM\nstate changes only when clock rises\nsimple regfile:\nvalA, valB, srcA, srcB, dstW, valW\nin the Y86 processor: a memory with 2 ports, one for R inst, the other for R/W data\n4.3 stages of instructions Fetch PC = memaddr\nvalP = PC + len(inst)\nDecode read operands from reg file\nExecute ALU performs instruction or incr/decr the stack pointer, for other instruction, similar\nMemory W/R data in mem\nWrite back write back to register\nPC update PC stores addr of next instruction\ncost of adding hardware \u0026gt; cost of copying code in software\nprocess similar instructions in same manners\nHardware Fetch: PC computes valP, the incremented PC.\nDecode: read valA and valB\nExecute: ALU calculates integer or increments the stack pointer, decides whether jump or not.\nMemory: read or write a word of mem\nWrite Back: write back from ALU or mem\nPC update\nonly start next cycle when clock rises\nprocessor never read back\neg: no instruction will both set and read the cond code\neg: stack pointer\nfetch: fetching 6 bytes and generate instruction fields.\ndecode \u0026amp; write back: generate register identifiers, serve necessary data.\nexecute: ALU performs as the calculator or just the adder.\nmemory: write or read memory values.\nPC increment: depend on instruction code or branch or not.\nSurvey the clock must run slow enough to suit the single-cycle.\nthe parts of the processor only active for a single part of time in the clock cycle\n4.4 pipelining divide into a series of discrete stages\nincrease the throughput of a system, but slightly increase the latency\nnonpipelined: a logic performs the computation with a register hold the result of the computation\nlatency: the total time to perform a single instruction\nslowing the clock won\u0026rsquo;t change the behavior of a pipeline.\ndifferent clock delays of different instructions influences the pipeline,\ndue to the delay, pipeline doesn\u0026rsquo;t always have larger throughput with more stages on each instruction\nlogical dependencies limits the performance of pipeline\n","date":"2024-12-10T16:44:47+08:00","permalink":"https://victorzhangai.github.io/p/csapp-chapter4/","title":"Csapp Chapter4"},{"content":"VZstless as your friend or thinker 🍥 Call this name as VictorZhang was signed up by somebody else\u0026hellip; 👻 Love frontend in any perspective, digital, or web. 🐣 Libre \u0026amp; OpenSource aholic. ⭐ Still an undergraduate and a crazyone. 🐧 A human-like history book or cheatsheet. ✉️ 2319725508@qq.com 🍀I work so I live. ","date":"2024-12-09T20:45:32+08:00","permalink":"https://victorzhangai.github.io/p/whoami/","title":"Whoami"}]